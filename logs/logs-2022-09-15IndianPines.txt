creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:13:08--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fdcbe412bd0>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:2.50, val_acc:0.53]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0   45    0    0    0    0    0
     0    0    0]
 [   0   19  516    0    0    3   20    3   15    4  203  529   54    0
    19    0    0]
 [   0   11  186    0    0    0   22   17    0   24  132  301   61    0
    51    0    0]
 [   0   24  114    0    0    0   39    7    0    0   46    0    0    0
     0    0    0]
 [   0    2    0    0    0    0   51    0   66    7   18    0    0    0
   325    0    0]
 [   0   13    0    0    0    0  628    0    0    0    0    1    0    0
    66    0    0]
 [   0    0    0    0    0    0    9    0   15    0    0    0    0    0
     3    0    0]
 [   0    0    0    0    0    0    0    0  464    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0   15    0    0    1    0    0    0    0
     3    0    0]
 [   0   68    3    0    0    0    6    2    1    0  328  439   13    0
    52   31    0]
 [   0  107    7    0    0    3   22   27   31   24   77 1651  390    0
    43    0    0]
 [   0    0  168    0    0    1    3   37    1    4   71   35  230    0
    18    3    4]
 [   0    0    0    0    0    0  198    0    0    0    0    0    0    0
     1    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
  1227    0    0]
 [   0    8    0    0    0   13   74    0    0    0    7    0    3    0
   265    4    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0   87    0
     0    0    3]]

Accuracy:
50.8147

F1 scores:
[   nan 0.     0.4338 0.     0.     0.     0.6997 0.     0.8421 0.0241
 0.3595 0.6186 0.3255 0.     0.7436 0.0194 0.0619]

Kappa:
0.4311
IndianPines数据集的结果如下
['0.0+-0.0' '43.38+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '69.97+-0.0'
 '0.0+-0.0' '84.21+-0.0' '2.41+-0.0' '35.95+-0.0' '61.86+-0.0'
 '32.55+-0.0' '0.0+-0.0' '74.36+-0.0' '1.94+-0.0' '6.19+-0.0']
acc_dataset [[50.81472541]]
OAMean 50.81 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:13:14--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7ffa1daa0dd0>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:2.36, val_acc:0.54]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    1    0   44    0    0    0    0    0
     0    0    0]
 [   0    0  542    0    0    1   46    0   48    0  131  597    6    2
    12    0    0]
 [   0    0   90    0    0    0   73    0   63    0  130  393    0    4
    52    0    0]
 [   0    0   80    0    0    0   46    0  102    0    0    2    0    0
     0    0    0]
 [   0    0    0    0    0    0  127    0   20    0    0    0    0    0
   322    0    0]
 [   0    0    0    0    0    0  615    0    0    0    0    2    0    0
    91    0    0]
 [   0    0    0    0    0    0   27    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0  464    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0   18    0    0    0    0    0    0    0
     1    0    0]
 [   0    0    9    0    0    6   63    0   40    0  284  510   12    0
    19    0    0]
 [   0    0  100    0    0    0  110    0   80    0   73 1784  185    0
    30    0   20]
 [   0   14  114    0    0    2   20    3  107    0   89   99   88    6
    12    0   21]
 [   0    0    0    0    0    0  193    0    0    0    0    0    0    0
     6    0    0]
 [   0    0    0    0    0    0    0    0    0    0    1    0    0    0
  1226    0    0]
 [   0    0    0    0    0    0   99    6   22    0    0    0    1    4
   242    0    0]
 [   0    0    0    0    0    0    0    0    0    0    2    0    0    0
     0    0   88]]

Accuracy:
51.2070

F1 scores:
[   nan 0.     0.4672 0.     0.     0.     0.5732 0.     0.6382 0.
 0.3436 0.6185 0.203  0.     0.7568 0.     0.8037]

Kappa:
0.4304
IndianPines数据集的结果如下
['0.0+-0.0' '46.72+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '57.32+-0.0'
 '0.0+-0.0' '63.82+-0.0' '0.0+-0.0' '34.36+-0.0' '61.85+-0.0' '20.3+-0.0'
 '0.0+-0.0' '75.68+-0.0' '0.0+-0.0' '80.37+-0.0']
acc_dataset [[51.2070006]]
OAMean 51.21 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:13:16--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:13:17--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f69f289bfd0>
supervision:full
center_pixel:True
Network :
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:13:28--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f455a2a73d0>
supervision:full
center_pixel:True
Network :
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:13:46--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f9299253410>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:13:48--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f2ce4150790>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:10--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fa74825b410>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:35--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7efd22ae0590>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:37--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f363b404790>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:41--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f5520af3450>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:42--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fed540594d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:43--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7ff8ba439250>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:44--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f5890e4a350>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:45--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fee3327e210>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:46--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f7d0b5e74d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:47--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f0d983862d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:48--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f34691443d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:48--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f430d8eb390>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:2.45, val_acc:0.34]
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:53--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f056cb18450>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:2.45, val_acc:0.27]
IndianPines数据集的结果如下
['0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0'
 '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0'
 '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0']
acc_dataset [[0.]]
OAMean 0.00 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:54--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fb9b280c4d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:2.41, val_acc:0.30]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0    0   31    0    0    0    0    0    0    0    0    0    0    0
    14    0    0]
 [   0    0 1234    0    0    0    0    0    0    0  111   27    0    0
    13    0    0]
 [   0    0  703    0    0    0    0    0    0    0   42   24    0    0
    36    0    0]
 [   0    0  219    0    0    0    0    0    0    0    0    4    0    0
     7    0    0]
 [   0    0   28    0    0    0    0    0    0    0    0    3    0    0
   438    0    0]
 [   0    0   17    0    0    0    0    0    0    0    0    1    0    0
   690    0    0]
 [   0    0   12    0    0    0    0    0    0    0    0    0    0    0
    15    0    0]
 [   0    0  440    0    0    0    0    0    0    0    0    0    0    0
    24    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    3    0    0
    16    0    0]
 [   0    0  653    0    0    0    0    0    0    0  235   28    0    0
    27    0    0]
 [   0    0 2003    0    0    0    0    0    0    0  249   78    0    0
    52    0    0]
 [   0    0  419    0    0    0    0    0    0    0  135    4    0    0
    17    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
   199    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
  1227    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
   374    0    0]
 [   0    0    5    0    0    0    0    0    0    0    0    0    0    0
    85    0    0]]

Accuracy:
27.9018

F1 scores:
[   nan 0.     0.3452 0.     0.     0.     0.     0.     0.     0.
 0.2741 0.0611 0.     0.     0.5501 0.     0.    ]

Kappa:
0.1690
IndianPines数据集的结果如下
['0.0+-0.0' '34.52+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0'
 '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '27.41+-0.0' '6.11+-0.0' '0.0+-0.0'
 '0.0+-0.0' '55.01+-0.0' '0.0+-0.0' '0.0+-0.0']
acc_dataset [[27.90183062]]
OAMean 27.90 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:55--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/train_gt.npy)
307 samples selected for training(over 10249)
Training Percentage:0.03
Load train_gt successfully!(PATH:../dataset/IndianPines/0.03/test_gt.npy)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
307 samples selected for training(over 10249)
9942 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:9
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.03
sample_nums:20
epoch:100
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000, 14.0000,  0.3256,  0.5600,  2.0000,  1.0000,  0.6364, 14.0000,
         1.0000, 14.0000,  0.4828,  0.1918,  0.7778,  2.3333,  0.3684,  1.1667,
         4.6667], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fa3dcf86b10>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/100    avg_loss:2.46, val_acc:0.31]
Epoch [2/100    avg_loss:1.96, val_acc:0.41]
Epoch [3/100    avg_loss:1.75, val_acc:0.43]
Epoch [4/100    avg_loss:1.66, val_acc:0.45]
Epoch [5/100    avg_loss:1.54, val_acc:0.54]
Epoch [6/100    avg_loss:1.32, val_acc:0.54]
Epoch [7/100    avg_loss:1.23, val_acc:0.58]
Epoch [8/100    avg_loss:1.13, val_acc:0.60]
Epoch [9/100    avg_loss:1.05, val_acc:0.59]
Epoch [10/100    avg_loss:0.87, val_acc:0.64]
Epoch [11/100    avg_loss:0.74, val_acc:0.69]
Epoch [12/100    avg_loss:0.70, val_acc:0.67]
Epoch [13/100    avg_loss:0.59, val_acc:0.68]
Epoch [14/100    avg_loss:0.50, val_acc:0.72]
Epoch [15/100    avg_loss:0.47, val_acc:0.74]
Epoch [16/100    avg_loss:0.36, val_acc:0.75]
Epoch [17/100    avg_loss:0.27, val_acc:0.75]
Epoch [18/100    avg_loss:0.27, val_acc:0.73]
Epoch [19/100    avg_loss:0.21, val_acc:0.76]
Epoch [20/100    avg_loss:0.26, val_acc:0.75]
Epoch [21/100    avg_loss:0.19, val_acc:0.76]
Epoch [22/100    avg_loss:0.12, val_acc:0.80]
Epoch [23/100    avg_loss:0.11, val_acc:0.79]
Epoch [24/100    avg_loss:0.15, val_acc:0.80]
Epoch [25/100    avg_loss:0.15, val_acc:0.78]
Epoch [26/100    avg_loss:0.10, val_acc:0.76]
Epoch [27/100    avg_loss:0.09, val_acc:0.80]
Epoch [28/100    avg_loss:0.04, val_acc:0.78]
Epoch [29/100    avg_loss:0.09, val_acc:0.79]
Epoch [30/100    avg_loss:0.05, val_acc:0.80]
Epoch [31/100    avg_loss:0.02, val_acc:0.81]
Epoch [32/100    avg_loss:0.06, val_acc:0.81]
Epoch [33/100    avg_loss:0.05, val_acc:0.79]
Epoch [34/100    avg_loss:0.02, val_acc:0.80]
Epoch [35/100    avg_loss:0.03, val_acc:0.80]
Epoch [36/100    avg_loss:0.02, val_acc:0.80]
Epoch [37/100    avg_loss:0.01, val_acc:0.81]
Epoch [38/100    avg_loss:0.03, val_acc:0.80]
Epoch [39/100    avg_loss:0.02, val_acc:0.81]
Epoch [40/100    avg_loss:0.01, val_acc:0.81]
Epoch [41/100    avg_loss:0.01, val_acc:0.81]
Epoch [42/100    avg_loss:0.01, val_acc:0.82]
IndianPines数据集的结果如下
['0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0'
 '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0'
 '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0']
acc_dataset [[0.]]
OAMean 0.00 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:55--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:100
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f2d87b4fa10>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/100    avg_loss:1.99, val_acc:0.36]
Epoch [2/100    avg_loss:1.52, val_acc:0.56]
Epoch [3/100    avg_loss:1.19, val_acc:0.61]
Epoch [4/100    avg_loss:0.98, val_acc:0.68]
Epoch [5/100    avg_loss:0.77, val_acc:0.75]
Epoch [6/100    avg_loss:0.62, val_acc:0.78]
Epoch [7/100    avg_loss:0.50, val_acc:0.86]
Epoch [8/100    avg_loss:0.36, val_acc:0.88]
Epoch [9/100    avg_loss:0.28, val_acc:0.91]
Epoch [10/100    avg_loss:0.18, val_acc:0.93]
Epoch [11/100    avg_loss:0.21, val_acc:0.91]
Epoch [12/100    avg_loss:0.16, val_acc:0.93]
Epoch [13/100    avg_loss:0.10, val_acc:0.94]
Epoch [14/100    avg_loss:0.10, val_acc:0.94]
Epoch [15/100    avg_loss:0.05, val_acc:0.94]
Epoch [16/100    avg_loss:0.05, val_acc:0.94]
Epoch [17/100    avg_loss:0.04, val_acc:0.96]
Epoch [18/100    avg_loss:0.06, val_acc:0.94]
Epoch [19/100    avg_loss:0.05, val_acc:0.95]
Epoch [20/100    avg_loss:0.07, val_acc:0.94]
Epoch [21/100    avg_loss:0.06, val_acc:0.95]
Epoch [22/100    avg_loss:0.07, val_acc:0.87]
Epoch [23/100    avg_loss:0.16, val_acc:0.91]
Epoch [24/100    avg_loss:0.10, val_acc:0.94]
Epoch [25/100    avg_loss:0.05, val_acc:0.94]
Epoch [26/100    avg_loss:0.04, val_acc:0.96]
Epoch [27/100    avg_loss:0.02, val_acc:0.95]
Epoch [28/100    avg_loss:0.01, val_acc:0.97]
Epoch [29/100    avg_loss:0.01, val_acc:0.97]
Epoch [30/100    avg_loss:0.01, val_acc:0.96]
Epoch [31/100    avg_loss:0.03, val_acc:0.94]
Epoch [32/100    avg_loss:0.05, val_acc:0.95]
Epoch [33/100    avg_loss:0.05, val_acc:0.95]
Epoch [34/100    avg_loss:0.04, val_acc:0.94]
Epoch [35/100    avg_loss:0.05, val_acc:0.96]
Epoch [36/100    avg_loss:0.02, val_acc:0.97]
Epoch [37/100    avg_loss:0.02, val_acc:0.95]
Epoch [38/100    avg_loss:0.01, val_acc:0.97]
Epoch [39/100    avg_loss:0.00, val_acc:0.97]
Epoch [40/100    avg_loss:0.01, val_acc:0.97]
Epoch [41/100    avg_loss:0.00, val_acc:0.97]
Epoch [42/100    avg_loss:0.00, val_acc:0.97]
Epoch [43/100    avg_loss:0.00, val_acc:0.98]
Epoch [44/100    avg_loss:0.00, val_acc:0.98]
Epoch [45/100    avg_loss:0.00, val_acc:0.98]
Epoch [46/100    avg_loss:0.00, val_acc:0.97]
Epoch [47/100    avg_loss:0.00, val_acc:0.98]
Epoch [48/100    avg_loss:0.00, val_acc:0.98]
Epoch [49/100    avg_loss:0.00, val_acc:0.98]
Epoch [50/100    avg_loss:0.01, val_acc:0.97]
Epoch [51/100    avg_loss:0.00, val_acc:0.98]
Epoch [52/100    avg_loss:0.00, val_acc:0.97]
Epoch [53/100    avg_loss:0.03, val_acc:0.94]
Epoch [54/100    avg_loss:0.36, val_acc:0.86]
Epoch [55/100    avg_loss:0.21, val_acc:0.92]
Epoch [56/100    avg_loss:0.09, val_acc:0.94]
Epoch [57/100    avg_loss:0.05, val_acc:0.95]
Epoch [58/100    avg_loss:0.01, val_acc:0.96]
Epoch [59/100    avg_loss:0.02, val_acc:0.97]
Epoch [60/100    avg_loss:0.01, val_acc:0.96]
Epoch [61/100    avg_loss:0.00, val_acc:0.97]
Epoch [62/100    avg_loss:0.01, val_acc:0.97]
Epoch [63/100    avg_loss:0.01, val_acc:0.97]
Epoch [64/100    avg_loss:0.01, val_acc:0.96]
Epoch [65/100    avg_loss:0.01, val_acc:0.96]
Epoch [66/100    avg_loss:0.00, val_acc:0.96]
Epoch [67/100    avg_loss:0.01, val_acc:0.97]
Epoch [68/100    avg_loss:0.00, val_acc:0.97]
Epoch [69/100    avg_loss:0.00, val_acc:0.97]
Epoch [70/100    avg_loss:0.00, val_acc:0.97]
Epoch [71/100    avg_loss:0.01, val_acc:0.96]
Epoch [72/100    avg_loss:0.06, val_acc:0.90]
Epoch [73/100    avg_loss:0.24, val_acc:0.92]
Epoch [74/100    avg_loss:0.16, val_acc:0.91]
Epoch [75/100    avg_loss:0.10, val_acc:0.95]
Epoch [76/100    avg_loss:0.07, val_acc:0.95]
Epoch [77/100    avg_loss:0.03, val_acc:0.95]
Epoch [78/100    avg_loss:0.04, val_acc:0.96]
Epoch [79/100    avg_loss:0.01, val_acc:0.94]
Epoch [80/100    avg_loss:0.01, val_acc:0.95]
Epoch [81/100    avg_loss:0.01, val_acc:0.96]
Epoch [82/100    avg_loss:0.00, val_acc:0.96]
Epoch [83/100    avg_loss:0.01, val_acc:0.96]
Epoch [84/100    avg_loss:0.01, val_acc:0.96]
Epoch [85/100    avg_loss:0.00, val_acc:0.97]
Epoch [86/100    avg_loss:0.00, val_acc:0.96]
Epoch [87/100    avg_loss:0.01, val_acc:0.97]
Epoch [88/100    avg_loss:0.00, val_acc:0.97]
Epoch [89/100    avg_loss:0.00, val_acc:0.97]
Epoch [90/100    avg_loss:0.00, val_acc:0.97]
Epoch [91/100    avg_loss:0.00, val_acc:0.97]
Epoch [92/100    avg_loss:0.00, val_acc:0.97]
Epoch [93/100    avg_loss:0.00, val_acc:0.97]
Epoch [94/100    avg_loss:0.01, val_acc:0.97]
Epoch [95/100    avg_loss:0.01, val_acc:0.97]
Epoch [96/100    avg_loss:0.00, val_acc:0.97]
Epoch [97/100    avg_loss:0.00, val_acc:0.98]
Epoch [98/100    avg_loss:0.00, val_acc:0.97]
Epoch [99/100    avg_loss:0.00, val_acc:0.98]
Epoch [100/100    avg_loss:0.01, val_acc:0.96]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0   37    1    0    0    0    0    0    3    0    0    0    0    0
     0    0    0]
 [   0    0 1245   20    3    0    0    0    0    0    5   12    0    0
     0    0    0]
 [   0    0   15  716    0    0    0    0    0    0    0    9    6    0
     1    0    0]
 [   0    0    5   14  192    0    0    0    2    0    0    0    0    0
     0    0    0]
 [   0    0    1    0    0  430    0    0    0    0    0    0    0    0
     4    0    0]
 [   0    0    0    0    0    0  657    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    1    0   24    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0  430    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0   18    0    0    0    0
     0    0    0]
 [   0    0    6    7    0    0    1    0    0    0  816   42    0    0
     2    1    0]
 [   0    0   20    5    0    0    0    0    0    0    5 2171    7    0
     1    1    0]
 [   0    0   25    4    0    0    0    0    0    0    0   10  495    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    1    0  184
     0    0    0]
 [   0    0    0    0    0    0    1    0    0    0    0    0    0    0
  1128   10    0]
 [   0    0    0    0    0    0    7    0    0    0    0    0    0    0
   102  238    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0   84]]

Accuracy:
96.0976

F1 scores:
[   nan 0.9487 0.9566 0.9465 0.9412 0.9931 0.9932 0.9796 0.9942 1.
 0.9594 0.9746 0.9501 0.9973 0.9491 0.7973 1.    ]

Kappa:
0.9554
IndianPines数据集的结果如下
['94.87+-0.0' '95.66+-0.0' '94.65+-0.0' '94.12+-0.0' '99.31+-0.0'
 '99.32+-0.0' '97.96+-0.0' '99.42+-0.0' '100.0+-0.0' '95.94+-0.0'
 '97.46+-0.0' '95.01+-0.0' '99.73+-0.0' '94.91+-0.0' '79.73+-0.0'
 '100.0+-0.0']
acc_dataset [[96.09756098]]
OAMean 96.10 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:14:56--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:100
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f3a1daa2310>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/100    avg_loss:2.06, val_acc:0.43]
Epoch [2/100    avg_loss:1.47, val_acc:0.54]
Epoch [3/100    avg_loss:1.22, val_acc:0.61]
Epoch [4/100    avg_loss:1.01, val_acc:0.71]
Epoch [5/100    avg_loss:0.81, val_acc:0.69]
Epoch [6/100    avg_loss:0.65, val_acc:0.78]
Epoch [7/100    avg_loss:0.50, val_acc:0.82]
Epoch [8/100    avg_loss:0.41, val_acc:0.84]
Epoch [9/100    avg_loss:0.32, val_acc:0.83]
Epoch [10/100    avg_loss:0.26, val_acc:0.87]
Epoch [11/100    avg_loss:0.17, val_acc:0.93]
Epoch [12/100    avg_loss:0.13, val_acc:0.93]
Epoch [13/100    avg_loss:0.09, val_acc:0.95]
Epoch [14/100    avg_loss:0.06, val_acc:0.93]
Epoch [15/100    avg_loss:0.08, val_acc:0.93]
Epoch [16/100    avg_loss:0.13, val_acc:0.93]
Epoch [17/100    avg_loss:0.07, val_acc:0.94]
Epoch [18/100    avg_loss:0.06, val_acc:0.95]
Epoch [19/100    avg_loss:0.05, val_acc:0.91]
Epoch [20/100    avg_loss:0.10, val_acc:0.89]
Epoch [21/100    avg_loss:0.11, val_acc:0.93]
Epoch [22/100    avg_loss:0.07, val_acc:0.92]
Epoch [23/100    avg_loss:0.06, val_acc:0.92]
Epoch [24/100    avg_loss:0.03, val_acc:0.93]
Epoch [25/100    avg_loss:0.05, val_acc:0.95]
Epoch [26/100    avg_loss:0.03, val_acc:0.95]
Epoch [27/100    avg_loss:0.02, val_acc:0.96]
Epoch [28/100    avg_loss:0.01, val_acc:0.96]
Epoch [29/100    avg_loss:0.01, val_acc:0.95]
Epoch [30/100    avg_loss:0.02, val_acc:0.95]
Epoch [31/100    avg_loss:0.01, val_acc:0.97]
Epoch [32/100    avg_loss:0.00, val_acc:0.97]
Epoch [33/100    avg_loss:0.07, val_acc:0.92]
Epoch [34/100    avg_loss:0.05, val_acc:0.94]
Epoch [35/100    avg_loss:0.03, val_acc:0.95]
Epoch [36/100    avg_loss:0.06, val_acc:0.95]
Epoch [37/100    avg_loss:0.03, val_acc:0.95]
Epoch [38/100    avg_loss:0.05, val_acc:0.94]
Epoch [39/100    avg_loss:0.07, val_acc:0.95]
Epoch [40/100    avg_loss:0.02, val_acc:0.97]
Epoch [41/100    avg_loss:0.01, val_acc:0.97]
Epoch [42/100    avg_loss:0.03, val_acc:0.95]
Epoch [43/100    avg_loss:0.06, val_acc:0.96]
Epoch [44/100    avg_loss:0.14, val_acc:0.92]
Epoch [45/100    avg_loss:0.08, val_acc:0.91]
Epoch [46/100    avg_loss:0.02, val_acc:0.95]
Epoch [47/100    avg_loss:0.02, val_acc:0.97]
Epoch [48/100    avg_loss:0.01, val_acc:0.97]
Epoch [49/100    avg_loss:0.00, val_acc:0.97]
Epoch [50/100    avg_loss:0.00, val_acc:0.97]
Epoch [51/100    avg_loss:0.00, val_acc:0.97]
Epoch [52/100    avg_loss:0.00, val_acc:0.97]
Epoch [53/100    avg_loss:0.00, val_acc:0.97]
Epoch [54/100    avg_loss:0.01, val_acc:0.95]
Epoch [55/100    avg_loss:0.07, val_acc:0.88]
Epoch [56/100    avg_loss:0.07, val_acc:0.92]
Epoch [57/100    avg_loss:0.10, val_acc:0.95]
Epoch [58/100    avg_loss:0.23, val_acc:0.87]
Epoch [59/100    avg_loss:0.23, val_acc:0.92]
Epoch [60/100    avg_loss:0.05, val_acc:0.95]
Epoch [61/100    avg_loss:0.03, val_acc:0.96]
Epoch [62/100    avg_loss:0.02, val_acc:0.96]
Epoch [63/100    avg_loss:0.03, val_acc:0.95]
Epoch [64/100    avg_loss:0.01, val_acc:0.95]
Epoch [65/100    avg_loss:0.01, val_acc:0.96]
Epoch [66/100    avg_loss:0.01, val_acc:0.96]
Epoch [67/100    avg_loss:0.00, val_acc:0.96]
Epoch [68/100    avg_loss:0.00, val_acc:0.95]
Epoch [69/100    avg_loss:0.01, val_acc:0.96]
Epoch [70/100    avg_loss:0.01, val_acc:0.95]
Epoch [71/100    avg_loss:0.01, val_acc:0.96]
Epoch [72/100    avg_loss:0.00, val_acc:0.96]
Epoch [73/100    avg_loss:0.01, val_acc:0.96]
Epoch [74/100    avg_loss:0.00, val_acc:0.97]
Epoch [75/100    avg_loss:0.00, val_acc:0.97]
Epoch [76/100    avg_loss:0.00, val_acc:0.96]
Epoch [77/100    avg_loss:0.00, val_acc:0.97]
Epoch [78/100    avg_loss:0.00, val_acc:0.97]
Epoch [79/100    avg_loss:0.00, val_acc:0.97]
Epoch [80/100    avg_loss:0.00, val_acc:0.96]
Epoch [81/100    avg_loss:0.00, val_acc:0.97]
Epoch [82/100    avg_loss:0.00, val_acc:0.97]
Epoch [83/100    avg_loss:0.00, val_acc:0.96]
Epoch [84/100    avg_loss:0.00, val_acc:0.97]
Epoch [85/100    avg_loss:0.00, val_acc:0.97]
Epoch [86/100    avg_loss:0.00, val_acc:0.97]
Epoch [87/100    avg_loss:0.00, val_acc:0.97]
Epoch [88/100    avg_loss:0.04, val_acc:0.94]
Epoch [89/100    avg_loss:0.04, val_acc:0.95]
Epoch [90/100    avg_loss:0.01, val_acc:0.96]
Epoch [91/100    avg_loss:0.01, val_acc:0.95]
Epoch [92/100    avg_loss:0.01, val_acc:0.95]
Epoch [93/100    avg_loss:0.00, val_acc:0.95]
Epoch [94/100    avg_loss:0.00, val_acc:0.95]
Epoch [95/100    avg_loss:0.00, val_acc:0.96]
Epoch [96/100    avg_loss:0.00, val_acc:0.96]
Epoch [97/100    avg_loss:0.00, val_acc:0.96]
Epoch [98/100    avg_loss:0.00, val_acc:0.96]
Epoch [99/100    avg_loss:0.00, val_acc:0.96]
Epoch [100/100    avg_loss:0.00, val_acc:0.97]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0   36    0    0    0    0    0    0    4    0    0    0    0    0
     0    0    1]
 [   0    0 1265    6    3    0    0    0    0    0    3    8    0    0
     0    0    0]
 [   0    0    0  718    0    0    0    0    0    0    0   20    9    0
     0    0    0]
 [   0    0    0   17  195    0    0    0    0    0    0    1    0    0
     0    0    0]
 [   0    0    1    0    0  428    0    0    0    0    0    1    0    0
     5    0    0]
 [   0    0    0    0    0    0  651    0    0    0    0    0    0    0
     6    0    0]
 [   0    0    0    0    0    0    0   25    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0  430    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    1    0    0   17    0    0    0    0
     0    0    0]
 [   0    0    9    1    0    0    1    0    0    0  811   50    0    0
     1    0    2]
 [   0    0   27   21    0    1    0    0    0    0    1 2142   17    0
     1    0    0]
 [   0    0    5    8    0    1    0    0    0    0    8    4  505    0
     0    0    3]
 [   0    0    0    0    0    0    0    0    0    0    0    3    0  182
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
  1126   13    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
   126  219    2]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0   84]]

Accuracy:
95.7615

F1 scores:
[   nan 0.9351 0.9761 0.946  0.9489 0.9896 0.9939 1.     0.9954 0.9714
 0.9552 0.9651 0.9484 0.9918 0.9368 0.7565 0.9545]

Kappa:
0.9516
IndianPines数据集的结果如下
['93.51+-0.0' '97.61+-0.0' '94.6+-0.0' '94.89+-0.0' '98.96+-0.0'
 '99.39+-0.0' '100.0+-0.0' '99.54+-0.0' '97.14+-0.0' '95.52+-0.0'
 '96.51+-0.0' '94.84+-0.0' '99.18+-0.0' '93.68+-0.0' '75.65+-0.0'
 '95.45+-0.0']
acc_dataset [[95.76151762]]
OAMean 95.76 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:15:19--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f61f21412d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:1.99, val_acc:0.41]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    2    0   39    0    0    0    0    0
     0    0    0]
 [   0    0   11    1    0    0    0    0    0    0    0 1273    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0  744    0    0
     3    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0  213    0    0
     0    0    0]
 [   0    0    5    0    0    0   67    0   43    0    0    8    0    0
   312    0    0]
 [   0    0    3    1    0    0  156    0    2    0    0    4    0    0
   491    0    0]
 [   0    0    0    0    0    0    1    0   24    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0  430    0    0    0    0    0
     0    0    0]
 [   0    0    0    1    0    0   11    0    0    0    0    0    0    0
     6    0    0]
 [   0    0    2    2    0    0    4    0    0    0    0  864    3    0
     0    0    0]
 [   0    0   26    1    0    0    6    0   14    0    0 2159    2    0
     0    0    2]
 [   0    0   32    0    0    0    6    0    9    0    0  482    5    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0   19    0    0
   166    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
  1139    0    0]
 [   0    0    0    0    0    0   51    0    0    0    0    0    0    0
   296    0    0]
 [   0    0    0    5    0    0    0    0    0    0    0   18    0    0
    57    0    4]]

Accuracy:
42.3198

F1 scores:
[   nan 0.     0.0161 0.     0.     0.     0.3247 0.     0.8678 0.
 0.     0.5402 0.0184 0.     0.6312 0.     0.0889]

Kappa:
0.2881
IndianPines数据集的结果如下
['0.0+-0.0' '1.61+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '32.47+-0.0'
 '0.0+-0.0' '86.78+-0.0' '0.0+-0.0' '0.0+-0.0' '54.02+-0.0' '1.84+-0.0'
 '0.0+-0.0' '63.12+-0.0' '0.0+-0.0' '8.89+-0.0']
acc_dataset [[42.3197832]]
OAMean 42.32 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:15:22--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fb30e4a8350>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:2.23, val_acc:0.37]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0   34    0    0    6    0    0
     1    0    0]
 [   0    0  325    0    0    0    0    0    0    0    0  955    0    0
     5    0    0]
 [   0    0  332    0    0    0    0    0    0    0    0  414    0    0
     1    0    0]
 [   0    0   22    0    0    0    0    0    0    0    0  191    0    0
     0    0    0]
 [   0    0    0    0    0    2    1    0   54    0    0   25    0    0
   353    0    0]
 [   0    0    0    0    0   10   48    0   10    0    0   55    0    0
   534    0    0]
 [   0    0    0    0    0    0    0    0   22    0    0    0    0    0
     3    0    0]
 [   0    0    0    0    0    0    0    0  430    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    2    0    0    0    0    9    0    0
     7    0    0]
 [   0    0  281    0    0    0    1    0    0    0    0  589    0    0
     4    0    0]
 [   0    0  257    0    0    1    1    0    0    0    0 1950    0    0
     1    0    0]
 [   0    0  108    0    0    0    0    0    0    0    0  426    0    0
     0    0    0]
 [   0    0    0    0    0    3    1    0    0    0    0    2    0    0
   179    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
  1139    0    0]
 [   0    0    0    0    0    2    5    0    0    0    0    6    0    0
   334    0    0]
 [   0    0    1    0    0    0    0    0    0    0    0   83    0    0
     0    0    0]]

Accuracy:
42.2114

F1 scores:
[   nan 0.     0.2489 0.     0.     0.0088 0.1341 0.     0.8776 0.
 0.     0.5635 0.     0.     0.6157 0.     0.    ]

Kappa:
0.2953
IndianPines数据集的结果如下
['0.0+-0.0' '24.89+-0.0' '0.0+-0.0' '0.0+-0.0' '0.88+-0.0' '13.41+-0.0'
 '0.0+-0.0' '87.76+-0.0' '0.0+-0.0' '0.0+-0.0' '56.35+-0.0' '0.0+-0.0'
 '0.0+-0.0' '61.57+-0.0' '0.0+-0.0' '0.0+-0.0']
acc_dataset [[42.21138211]]
OAMean 42.21 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:15:28--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f59f6834310>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:2.13, val_acc:0.40]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    4    0    0    0    6    0   30    0    0    1    0    0
     0    0    0]
 [   0    0   32    0    0    0    0    0    0    0    0 1248    0    0
     5    0    0]
 [   0    0    0    2    0    5    0    0    0    0    0  738    0    0
     2    0    0]
 [   0    0   44    0    0    1    0    0    0    0    0  168    0    0
     0    0    0]
 [   0    0    4    0    0    8  102    0    9    0    0   15    0    0
   297    0    0]
 [   0    0    0    0    0   40  278    0    4    0    0   22    0    0
   313    0    0]
 [   0    0    0    0    0    2    9    0   13    0    0    0    0    0
     1    0    0]
 [   0    0    0    0    0    0    5    0  425    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0   17    0    0    0    0    1    0    0
     0    0    0]
 [   0    0    0    1    0    2    2    0    0    0    0  864    0    0
     6    0    0]
 [   0    0    1    2    0    5    5    0    0    0    6 2189    0    0
     2    0    0]
 [   0    0   61    0    0    3    6    0    0    0    0  464    0    0
     0    0    0]
 [   0    0    0    0    0    9    6    0    0    0    0    0    0    0
   170    0    0]
 [   0    0    0    0    0    0    2    0    0    0    0    0    0    0
  1137    0    0]
 [   0    0    0    0    0    0   98    0    0    0    0    0    0    0
   249    0    0]
 [   0    0    0    0    0    0    0    0    0    0   62   20    0    0
     2    0    0]]

Accuracy:
44.1301

F1 scores:
[   nan 0.     0.0447 0.0053 0.     0.0314 0.4661 0.     0.933  0.
 0.     0.5514 0.     0.     0.6843 0.     0.    ]

Kappa:
0.3120
IndianPines数据集的结果如下
['0.0+-0.0' '4.47+-0.0' '0.53+-0.0' '0.0+-0.0' '3.14+-0.0' '46.61+-0.0'
 '0.0+-0.0' '93.3+-0.0' '0.0+-0.0' '0.0+-0.0' '55.14+-0.0' '0.0+-0.0'
 '0.0+-0.0' '68.43+-0.0' '0.0+-0.0' '0.0+-0.0']
acc_dataset [[44.1300813]]
OAMean 44.13 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:16:48--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:16:51--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f1a9f772090>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:16:54--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f7b7b2f7cd0>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:16:59--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f35861e7650>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:17:19--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f439a6a74d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:17:19--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fccc7fae710>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:17:24--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fcf6f42f650>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:2.08, val_acc:0.44]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0   33    0    0    3    0    0
     5    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0 1280    0    0
     5    0    0]
 [   0    0    0    0    0    0    2    0    0    0    0  742    0    0
     3    0    0]
 [   0    0    0    0    0    0    1    0    0    0    0  212    0    0
     0    0    0]
 [   0    0    0    0    0    0   18    0   51    0    0   18    0    0
   348    0    0]
 [   0    0    0    0    0    0  195    0   21    0    0   21    0    0
   420    0    0]
 [   0    0    0    0    0    0    0    0   21    0    0    0    0    0
     4    0    0]
 [   0    0    0    0    0    0    0    0  429    0    0    0    0    0
     1    0    0]
 [   0    0    0    0    0    0   16    0    0    0    0    2    0    0
     0    0    0]
 [   0    0    0    0    0    0    5    0    0    0    0  867    0    0
     3    0    0]
 [   0    0    0    0    0    0    8    0    0    0    0 2200    0    0
     2    0    0]
 [   0    0    0    0    0    0    3    0    0    0    0  530    0    0
     1    0    0]
 [   0    0    0    0    0    0   27    0    0    0    0    1    0    0
   157    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
  1139    0    0]
 [   0    0    0    0    0    0   36    0    0    0    0    0    0    0
   311    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0   82    0    0
     0    0    2]]

Accuracy:
42.9810

F1 scores:
[   nan 0.     0.     0.     0.     0.     0.4029 0.     0.8711 0.
 0.     0.5387 0.     0.     0.6439 0.     0.0465]

Kappa:
0.2943
IndianPines数据集的结果如下
['0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '40.29+-0.0'
 '0.0+-0.0' '87.11+-0.0' '0.0+-0.0' '0.0+-0.0' '53.87+-0.0' '0.0+-0.0'
 '0.0+-0.0' '64.39+-0.0' '0.0+-0.0' '4.65+-0.0']
acc_dataset [[42.98102981]]
OAMean 42.98 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:17:24--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:100
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f67a9e2e550>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/100    avg_loss:2.00, val_acc:0.41]
Epoch [2/100    avg_loss:1.54, val_acc:0.52]
Epoch [3/100    avg_loss:1.30, val_acc:0.59]
Epoch [4/100    avg_loss:1.09, val_acc:0.66]
Epoch [5/100    avg_loss:0.93, val_acc:0.71]
Epoch [6/100    avg_loss:0.80, val_acc:0.73]
Epoch [7/100    avg_loss:0.67, val_acc:0.76]
Epoch [8/100    avg_loss:0.53, val_acc:0.79]
Epoch [9/100    avg_loss:0.41, val_acc:0.85]
Epoch [10/100    avg_loss:0.28, val_acc:0.86]
Epoch [11/100    avg_loss:0.25, val_acc:0.89]
Epoch [12/100    avg_loss:0.13, val_acc:0.92]
Epoch [13/100    avg_loss:0.11, val_acc:0.93]
Epoch [14/100    avg_loss:0.08, val_acc:0.87]
Epoch [15/100    avg_loss:0.21, val_acc:0.92]
Epoch [16/100    avg_loss:0.10, val_acc:0.94]
Epoch [17/100    avg_loss:0.07, val_acc:0.93]
Epoch [18/100    avg_loss:0.09, val_acc:0.94]
Epoch [19/100    avg_loss:0.04, val_acc:0.93]
Epoch [20/100    avg_loss:0.03, val_acc:0.95]
Epoch [21/100    avg_loss:0.17, val_acc:0.87]
Epoch [22/100    avg_loss:0.18, val_acc:0.91]
Epoch [23/100    avg_loss:0.07, val_acc:0.95]
Epoch [24/100    avg_loss:0.02, val_acc:0.96]
Epoch [25/100    avg_loss:0.01, val_acc:0.96]
Epoch [26/100    avg_loss:0.01, val_acc:0.95]
Epoch [27/100    avg_loss:0.06, val_acc:0.94]
Epoch [28/100    avg_loss:0.03, val_acc:0.93]
Epoch [29/100    avg_loss:0.02, val_acc:0.96]
Epoch [30/100    avg_loss:0.00, val_acc:0.96]
Epoch [31/100    avg_loss:0.00, val_acc:0.97]
Epoch [32/100    avg_loss:0.00, val_acc:0.95]
Epoch [33/100    avg_loss:0.04, val_acc:0.95]
Epoch [34/100    avg_loss:0.02, val_acc:0.95]
Epoch [35/100    avg_loss:0.01, val_acc:0.95]
Epoch [36/100    avg_loss:0.01, val_acc:0.95]
Epoch [37/100    avg_loss:0.01, val_acc:0.96]
Epoch [38/100    avg_loss:0.08, val_acc:0.92]
Epoch [39/100    avg_loss:0.07, val_acc:0.93]
Epoch [40/100    avg_loss:0.10, val_acc:0.94]
Epoch [41/100    avg_loss:0.16, val_acc:0.92]
Epoch [42/100    avg_loss:0.07, val_acc:0.94]
Epoch [43/100    avg_loss:0.05, val_acc:0.95]
Epoch [44/100    avg_loss:0.01, val_acc:0.95]
Epoch [45/100    avg_loss:0.00, val_acc:0.96]
Epoch [46/100    avg_loss:0.00, val_acc:0.96]
Epoch [47/100    avg_loss:0.00, val_acc:0.96]
Epoch [48/100    avg_loss:0.01, val_acc:0.97]
Epoch [49/100    avg_loss:0.03, val_acc:0.93]
Epoch [50/100    avg_loss:0.12, val_acc:0.94]
Epoch [51/100    avg_loss:0.05, val_acc:0.94]
Epoch [52/100    avg_loss:0.03, val_acc:0.93]
Epoch [53/100    avg_loss:0.02, val_acc:0.96]
Epoch [54/100    avg_loss:0.01, val_acc:0.95]
Epoch [55/100    avg_loss:0.01, val_acc:0.97]
Epoch [56/100    avg_loss:0.00, val_acc:0.96]
Epoch [57/100    avg_loss:0.01, val_acc:0.97]
Epoch [58/100    avg_loss:0.00, val_acc:0.97]
Epoch [59/100    avg_loss:0.00, val_acc:0.97]
Epoch [60/100    avg_loss:0.01, val_acc:0.96]
Epoch [61/100    avg_loss:0.01, val_acc:0.96]
Epoch [62/100    avg_loss:0.01, val_acc:0.96]
Epoch [63/100    avg_loss:0.01, val_acc:0.96]
Epoch [64/100    avg_loss:0.00, val_acc:0.97]
Epoch [65/100    avg_loss:0.00, val_acc:0.97]
Epoch [66/100    avg_loss:0.00, val_acc:0.97]
Epoch [67/100    avg_loss:0.00, val_acc:0.97]
Epoch [68/100    avg_loss:0.00, val_acc:0.97]
Epoch [69/100    avg_loss:0.00, val_acc:0.97]
Epoch [70/100    avg_loss:0.00, val_acc:0.97]
Epoch [71/100    avg_loss:0.00, val_acc:0.97]
Epoch [72/100    avg_loss:0.00, val_acc:0.97]
Epoch [73/100    avg_loss:0.00, val_acc:0.97]
Epoch [74/100    avg_loss:0.00, val_acc:0.97]
Epoch [75/100    avg_loss:0.00, val_acc:0.97]
Epoch [76/100    avg_loss:0.00, val_acc:0.98]
Epoch [77/100    avg_loss:0.00, val_acc:0.97]
Epoch [78/100    avg_loss:0.00, val_acc:0.98]
Epoch [79/100    avg_loss:0.00, val_acc:0.97]
Epoch [80/100    avg_loss:0.00, val_acc:0.98]
Epoch [81/100    avg_loss:0.00, val_acc:0.98]
Epoch [82/100    avg_loss:0.00, val_acc:0.97]
Epoch [83/100    avg_loss:0.00, val_acc:0.97]
Epoch [84/100    avg_loss:0.00, val_acc:0.98]
Epoch [85/100    avg_loss:0.00, val_acc:0.98]
Epoch [86/100    avg_loss:0.00, val_acc:0.98]
Epoch [87/100    avg_loss:0.00, val_acc:0.97]
Epoch [88/100    avg_loss:0.00, val_acc:0.97]
Epoch [89/100    avg_loss:0.00, val_acc:0.97]
Epoch [90/100    avg_loss:0.35, val_acc:0.89]
Epoch [91/100    avg_loss:0.43, val_acc:0.87]
Epoch [92/100    avg_loss:0.10, val_acc:0.94]
Epoch [93/100    avg_loss:0.10, val_acc:0.92]
Epoch [94/100    avg_loss:0.05, val_acc:0.91]
Epoch [95/100    avg_loss:0.05, val_acc:0.90]
Epoch [96/100    avg_loss:0.06, val_acc:0.92]
Epoch [97/100    avg_loss:0.09, val_acc:0.94]
Epoch [98/100    avg_loss:0.06, val_acc:0.94]
Epoch [99/100    avg_loss:0.07, val_acc:0.94]
Epoch [100/100    avg_loss:0.09, val_acc:0.95]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0   40    0    0    0    0    0    0    0    0    0    0    1    0
     0    0    0]
 [   0    0 1221   44    1    0    0    0    0    0    5    9    2    0
     3    0    0]
 [   0    0    2  727   10    0    0    0    0    0    1    0    7    0
     0    0    0]
 [   0    0    0   19  179    0    0    0    0    0    0    0   15    0
     0    0    0]
 [   0    1    5    0    2  420    0    0    0    0    0    1    0    0
     6    0    0]
 [   0    0    0    0    0    0  656    0    0    0    0    0    0    0
     1    0    0]
 [   0    1    0    0    0    7    0   17    0    0    0    0    0    0
     0    0    0]
 [   0   10    0    0    0    0    0    0  420    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    2    1    0    0    7    5    0    0    3
     0    0    0]
 [   0    0   20    4    0    0    3    0    0    0  796   48    3    0
     1    0    0]
 [   0    0   43   86    0    0    3    0    0    0   19 2029   29    1
     0    0    0]
 [   0    0    0    6    0    0    0    0    0    0    0    0  527    0
     0    1    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0  185
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
  1122   17    0]
 [   0    0    0    0    0    0    0    0    0    0    0    2    0    0
   121  224    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    6    0
     0    0   78]]

Accuracy:
93.7453

F1 scores:
[   nan 0.8602 0.948  0.8904 0.884  0.9722 0.9939 0.8095 0.9882 0.56
 0.9359 0.9439 0.9377 0.9893 0.9377 0.7606 0.963 ]

Kappa:
0.9288
IndianPines数据集的结果如下
['86.02+-0.0' '94.8+-0.0' '89.04+-0.0' '88.4+-0.0' '97.22+-0.0'
 '99.39+-0.0' '80.95+-0.0' '98.82+-0.0' '56.0+-0.0' '93.59+-0.0'
 '94.39+-0.0' '93.77+-0.0' '98.93+-0.0' '93.77+-0.0' '76.06+-0.0'
 '96.3+-0.0']
acc_dataset [[93.74525745]]
OAMean 93.75 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:17:28--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:100
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f751ab05390>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/100    avg_loss:2.06, val_acc:0.40]
Epoch [2/100    avg_loss:1.59, val_acc:0.53]
Epoch [3/100    avg_loss:1.30, val_acc:0.58]
Epoch [4/100    avg_loss:1.11, val_acc:0.63]
Epoch [5/100    avg_loss:0.90, val_acc:0.67]
Epoch [6/100    avg_loss:0.79, val_acc:0.74]
Epoch [7/100    avg_loss:0.64, val_acc:0.76]
Epoch [8/100    avg_loss:0.52, val_acc:0.80]
Epoch [9/100    avg_loss:0.47, val_acc:0.85]
Epoch [10/100    avg_loss:0.32, val_acc:0.89]
Epoch [11/100    avg_loss:0.19, val_acc:0.87]
Epoch [12/100    avg_loss:0.19, val_acc:0.89]
Epoch [13/100    avg_loss:0.15, val_acc:0.92]
Epoch [14/100    avg_loss:0.18, val_acc:0.89]
Epoch [15/100    avg_loss:0.16, val_acc:0.91]
Epoch [16/100    avg_loss:0.10, val_acc:0.91]
Epoch [17/100    avg_loss:0.10, val_acc:0.93]
Epoch [18/100    avg_loss:0.07, val_acc:0.93]
Epoch [19/100    avg_loss:0.04, val_acc:0.95]
Epoch [20/100    avg_loss:0.01, val_acc:0.96]
Epoch [21/100    avg_loss:0.02, val_acc:0.94]
Epoch [22/100    avg_loss:0.03, val_acc:0.93]
Epoch [23/100    avg_loss:0.05, val_acc:0.94]
Epoch [24/100    avg_loss:0.08, val_acc:0.90]
Epoch [25/100    avg_loss:0.11, val_acc:0.91]
Epoch [26/100    avg_loss:0.11, val_acc:0.93]
Epoch [27/100    avg_loss:0.06, val_acc:0.94]
Epoch [28/100    avg_loss:0.03, val_acc:0.94]
Epoch [29/100    avg_loss:0.03, val_acc:0.95]
Epoch [30/100    avg_loss:0.05, val_acc:0.92]
Epoch [31/100    avg_loss:0.06, val_acc:0.94]
Epoch [32/100    avg_loss:0.01, val_acc:0.95]
Epoch [33/100    avg_loss:0.02, val_acc:0.96]
Epoch [34/100    avg_loss:0.03, val_acc:0.93]
Epoch [35/100    avg_loss:0.02, val_acc:0.94]
Epoch [36/100    avg_loss:0.04, val_acc:0.94]
Epoch [37/100    avg_loss:0.12, val_acc:0.93]
Epoch [38/100    avg_loss:0.08, val_acc:0.96]
Epoch [39/100    avg_loss:0.04, val_acc:0.95]
Epoch [40/100    avg_loss:0.01, val_acc:0.95]
Epoch [41/100    avg_loss:0.01, val_acc:0.96]
Epoch [42/100    avg_loss:0.01, val_acc:0.96]
Epoch [43/100    avg_loss:0.00, val_acc:0.96]
Epoch [44/100    avg_loss:0.00, val_acc:0.96]
Epoch [45/100    avg_loss:0.01, val_acc:0.94]
Epoch [46/100    avg_loss:0.08, val_acc:0.94]
Epoch [47/100    avg_loss:0.03, val_acc:0.93]
Epoch [48/100    avg_loss:0.06, val_acc:0.94]
Epoch [49/100    avg_loss:0.03, val_acc:0.95]
Epoch [50/100    avg_loss:0.03, val_acc:0.90]
Epoch [51/100    avg_loss:0.17, val_acc:0.91]
Epoch [52/100    avg_loss:0.06, val_acc:0.91]
Epoch [53/100    avg_loss:0.10, val_acc:0.93]
Epoch [54/100    avg_loss:0.04, val_acc:0.94]
Epoch [55/100    avg_loss:0.04, val_acc:0.93]
Epoch [56/100    avg_loss:0.04, val_acc:0.95]
Epoch [57/100    avg_loss:0.02, val_acc:0.93]
Epoch [58/100    avg_loss:0.00, val_acc:0.94]
Epoch [59/100    avg_loss:0.00, val_acc:0.95]
Epoch [60/100    avg_loss:0.00, val_acc:0.95]
Epoch [61/100    avg_loss:0.01, val_acc:0.95]
Epoch [62/100    avg_loss:0.00, val_acc:0.96]
Epoch [63/100    avg_loss:0.00, val_acc:0.95]
Epoch [64/100    avg_loss:0.00, val_acc:0.96]
Epoch [65/100    avg_loss:0.00, val_acc:0.95]
Epoch [66/100    avg_loss:0.00, val_acc:0.96]
Epoch [67/100    avg_loss:0.00, val_acc:0.95]
Epoch [68/100    avg_loss:0.00, val_acc:0.96]
Epoch [69/100    avg_loss:0.00, val_acc:0.97]
Epoch [70/100    avg_loss:0.00, val_acc:0.95]
Epoch [71/100    avg_loss:0.00, val_acc:0.97]
Epoch [72/100    avg_loss:0.00, val_acc:0.96]
Epoch [73/100    avg_loss:0.00, val_acc:0.96]
Epoch [74/100    avg_loss:0.00, val_acc:0.97]
Epoch [75/100    avg_loss:0.00, val_acc:0.96]
Epoch [76/100    avg_loss:0.00, val_acc:0.97]
Epoch [77/100    avg_loss:0.00, val_acc:0.97]
Epoch [78/100    avg_loss:0.00, val_acc:0.98]
Epoch [79/100    avg_loss:0.00, val_acc:0.97]
Epoch [80/100    avg_loss:0.00, val_acc:0.96]
Epoch [81/100    avg_loss:0.00, val_acc:0.97]
Epoch [82/100    avg_loss:0.00, val_acc:0.97]
Epoch [83/100    avg_loss:0.00, val_acc:0.97]
Epoch [84/100    avg_loss:0.00, val_acc:0.96]
Epoch [85/100    avg_loss:0.00, val_acc:0.96]
Epoch [86/100    avg_loss:0.00, val_acc:0.96]
Epoch [87/100    avg_loss:0.00, val_acc:0.97]
Epoch [88/100    avg_loss:0.00, val_acc:0.97]
Epoch [89/100    avg_loss:0.01, val_acc:0.96]
Epoch [90/100    avg_loss:0.00, val_acc:0.97]
Epoch [91/100    avg_loss:0.00, val_acc:0.97]
Epoch [92/100    avg_loss:0.00, val_acc:0.97]
Epoch [93/100    avg_loss:0.00, val_acc:0.96]
Epoch [94/100    avg_loss:0.00, val_acc:0.96]
Epoch [95/100    avg_loss:0.00, val_acc:0.97]
Epoch [96/100    avg_loss:0.00, val_acc:0.96]
Epoch [97/100    avg_loss:0.00, val_acc:0.96]
Epoch [98/100    avg_loss:0.00, val_acc:0.96]
Epoch [99/100    avg_loss:0.00, val_acc:0.97]
Epoch [100/100    avg_loss:0.00, val_acc:0.96]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0   30    0    0    0    0    0    0   11    0    0    0    0    0
     0    0    0]
 [   0    0 1236    9    0    0    0    0    0    0    9   27    4    0
     0    0    0]
 [   0    0    0  721    0    0    0    0    0    0    0    6   20    0
     0    0    0]
 [   0    0    9    5  198    0    0    0    0    0    0    0    1    0
     0    0    0]
 [   0    0    4    0    0  426    0    0    0    0    0    0    0    0
     5    0    0]
 [   0    0    0    0    0    0  655    0    0    0    0    0    0    0
     1    1    0]
 [   0    0    0    0    0    1    0   24    0    0    0    0    0    0
     0    0    0]
 [   0    2    0    0    0    0    0    0  428    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    4    0    0   11    0    0    0    0
     0    3    0]
 [   0    0   22    7    0    0    0    0    0    0  820   22    1    0
     1    2    0]
 [   0    0   16   34    0    0    0    0    0    0    9 2124   27    0
     0    0    0]
 [   0    0    9    7    0    0    0    0    0    0    4    1  510    0
     0    0    3]
 [   0    0    0    0    0    0    0    0    0    0    0    1    0  184
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
  1131    8    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
    67  274    6]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0   84]]

Accuracy:
96.0000

F1 scores:
[   nan 0.8219 0.9578 0.9425 0.9635 0.9884 0.9954 0.9796 0.985  0.7586
 0.9552 0.9674 0.9298 0.9973 0.965  0.863  0.9492]

Kappa:
0.9544
IndianPines数据集的结果如下
['82.19+-0.0' '95.78+-0.0' '94.25+-0.0' '96.35+-0.0' '98.84+-0.0'
 '99.54+-0.0' '97.96+-0.0' '98.5+-0.0' '75.86+-0.0' '95.52+-0.0'
 '96.74+-0.0' '92.98+-0.0' '99.73+-0.0' '96.5+-0.0' '86.3+-0.0'
 '94.92+-0.0']
acc_dataset [[96.]]
OAMean 96.00 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:19:22--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f28e286ab90>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:2.01, val_acc:0.41]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    2    0   37    0    0    2    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0 1280    0    0
     5    0    0]
 [   0    0    0    0    0    0    5    0    0    0    0  739    0    0
     3    0    0]
 [   0    0    0    0    0    0    0    0    1    0    0  212    0    0
     0    0    0]
 [   0    0    0    0    0    0   68    0   52    0    0   15    0    0
   300    0    0]
 [   0    0    0    0    0    0  248    0   33    0    0    6    0    0
   370    0    0]
 [   0    0    0    0    0    0    0    0   24    0    0    0    0    0
     1    0    0]
 [   0    0    0    0    0    0    0    0  430    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0   18    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    2    0    0    0    0  868    0    0
     5    0    0]
 [   0    0    0    0    0    0    9    0    1    0    0 2198    0    0
     2    0    0]
 [   0    0    0    0    0    0    2    0    0    0    0  530    0    0
     2    0    0]
 [   0    0    0    0    0    0   19    0    0    0    0    3    0    0
   163    0    0]
 [   0    0    0    0    0    0    1    0    0    0    0    0    0    0
  1138    0    0]
 [   0    0    0    0    0    0   49    0    0    0    0    0    0    0
   298    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0   61    0    0
     2    0   21]]

Accuracy:
43.7398

F1 scores:
[   nan 0.     0.     0.     0.     0.     0.4593 0.     0.8532 0.
 0.     0.5411 0.     0.     0.6639 0.     0.4   ]

Kappa:
0.3051
IndianPines数据集的结果如下
['0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '45.93+-0.0'
 '0.0+-0.0' '85.32+-0.0' '0.0+-0.0' '0.0+-0.0' '54.11+-0.0' '0.0+-0.0'
 '0.0+-0.0' '66.39+-0.0' '0.0+-0.0' '40.0+-0.0']
acc_dataset [[43.7398374]]
OAMean 43.74 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:19:28--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fe6df7156d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:2.03, val_acc:0.43]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    7    0   33    0    0    1    0    0
     0    0    0]
 [   0    0   13    0    0    0    1    0    1    0    0 1270    0    0
     0    0    0]
 [   0    0    4    0    0    0   11    0    0    0    0  732    0    0
     0    0    0]
 [   0    0    7    0    0    0    1    0    0    0    0  205    0    0
     0    0    0]
 [   0    0    0    0    0    0   80    0   47    0    0   15    0    0
   293    0    0]
 [   0    0   11    0    0    0  422    0   47    0    0    1    0    0
   176    0    0]
 [   0    0    0    0    0    0    1    0   24    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    1    0  429    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0   17    0    0    0    0    1    0    0
     0    0    0]
 [   0    0   22    0    0    0   11    0    3    0    0  839    0    0
     0    0    0]
 [   0    0   23    0    0    0   12    0    3    0    0 2171    0    0
     1    0    0]
 [   0    0   20    0    0    0    3    0    0    0    0  511    0    0
     0    0    0]
 [   0    0    9    0    0    0   83    0   16    0    0    0    0    0
    77    0    0]
 [   0    0    0    0    0    0    1    0    0    0    0    0    0    0
  1138    0    0]
 [   0    0    0    0    0    0  145    0    3    0    0    0    0    0
   199    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0   84    0    0
     0    0    0]]

Accuracy:
45.2358

F1 scores:
[   nan 0.     0.0187 0.     0.     0.     0.5809 0.     0.8282 0.
 0.     0.54   0.     0.     0.7529 0.     0.    ]

Kappa:
0.3260
IndianPines数据集的结果如下
['0.0+-0.0' '1.87+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '58.09+-0.0'
 '0.0+-0.0' '82.82+-0.0' '0.0+-0.0' '0.0+-0.0' '54.0+-0.0' '0.0+-0.0'
 '0.0+-0.0' '75.29+-0.0' '0.0+-0.0' '0.0+-0.0']
acc_dataset [[45.23577236]]
OAMean 45.24 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:19:45--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:19:46--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:19:56--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f42d40ef450>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:19:57--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f9a3a08b910>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:19:59--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f151d6577d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:01--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fdcb2b45dd0>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:03--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f90f38d7690>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:04--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f4f5c932350>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:07--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f55f9c6d910>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:09--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7faaeb345810>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:10--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f63dafc3710>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:2.09, val_acc:0.37]
IndianPines数据集的结果如下
['0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0'
 '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0'
 '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0']
acc_dataset [[0.]]
OAMean 0.00 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:14--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f70c50fa7d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:2.03, val_acc:0.39]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0   41    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0 1285    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0  746    0    0
     1    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0  213    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0   84    0    0   17    0    0
   334    0    0]
 [   0    0    0    0    0    0    0    0   56    0    0   29    0    0
   572    0    0]
 [   0    0    0    0    0    0    0    0   25    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0  430    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    5    0    0
    13    0    0]
 [   0    0    0    0    0    0    0    0    2    0    0  873    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    1    0    0 2208    0    0
     1    0    0]
 [   0    0    0    0    0    0    0    0    6    0    0  528    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0   26    0    0
   159    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
  1139    0    0]
 [   0    0    0    0    0    0    0    0   35    0    0    2    0    0
   310    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0   84    0    0
     0    0    0]]

Accuracy:
40.9431

F1 scores:
[   nan 0.     0.     0.     0.     0.     0.     0.     0.7748 0.
 0.     0.5368 0.     0.     0.621  0.     0.    ]

Kappa:
0.2677
IndianPines数据集的结果如下
['0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0'
 '0.0+-0.0' '77.48+-0.0' '0.0+-0.0' '0.0+-0.0' '53.68+-0.0' '0.0+-0.0'
 '0.0+-0.0' '62.1+-0.0' '0.0+-0.0' '0.0+-0.0']
acc_dataset [[40.94308943]]
OAMean 40.94 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:14--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:100
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f46ecf673d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/100    avg_loss:2.06, val_acc:0.41]
Epoch [2/100    avg_loss:1.63, val_acc:0.46]
Epoch [3/100    avg_loss:1.43, val_acc:0.50]
Epoch [4/100    avg_loss:1.20, val_acc:0.58]
Epoch [5/100    avg_loss:1.06, val_acc:0.67]
Epoch [6/100    avg_loss:0.89, val_acc:0.67]
Epoch [7/100    avg_loss:0.74, val_acc:0.77]
Epoch [8/100    avg_loss:0.54, val_acc:0.78]
Epoch [9/100    avg_loss:0.45, val_acc:0.83]
Epoch [10/100    avg_loss:0.34, val_acc:0.86]
Epoch [11/100    avg_loss:0.28, val_acc:0.86]
Epoch [12/100    avg_loss:0.27, val_acc:0.91]
Epoch [13/100    avg_loss:0.19, val_acc:0.90]
Epoch [14/100    avg_loss:0.21, val_acc:0.91]
Epoch [15/100    avg_loss:0.14, val_acc:0.91]
Epoch [16/100    avg_loss:0.14, val_acc:0.93]
Epoch [17/100    avg_loss:0.10, val_acc:0.95]
Epoch [18/100    avg_loss:0.08, val_acc:0.93]
Epoch [19/100    avg_loss:0.08, val_acc:0.95]
Epoch [20/100    avg_loss:0.09, val_acc:0.94]
Epoch [21/100    avg_loss:0.07, val_acc:0.95]
Epoch [22/100    avg_loss:0.05, val_acc:0.94]
Epoch [23/100    avg_loss:0.06, val_acc:0.95]
Epoch [24/100    avg_loss:0.02, val_acc:0.95]
Epoch [25/100    avg_loss:0.04, val_acc:0.94]
Epoch [26/100    avg_loss:0.05, val_acc:0.94]
Epoch [27/100    avg_loss:0.05, val_acc:0.92]
Epoch [28/100    avg_loss:0.09, val_acc:0.94]
Epoch [29/100    avg_loss:0.11, val_acc:0.95]
Epoch [30/100    avg_loss:0.07, val_acc:0.93]
Epoch [31/100    avg_loss:0.06, val_acc:0.95]
Epoch [32/100    avg_loss:0.04, val_acc:0.95]
Epoch [33/100    avg_loss:0.02, val_acc:0.96]
Epoch [34/100    avg_loss:0.02, val_acc:0.97]
Epoch [35/100    avg_loss:0.02, val_acc:0.94]
Epoch [36/100    avg_loss:0.05, val_acc:0.96]
Epoch [37/100    avg_loss:0.02, val_acc:0.95]
Epoch [38/100    avg_loss:0.05, val_acc:0.93]
Epoch [39/100    avg_loss:0.06, val_acc:0.95]
Epoch [40/100    avg_loss:0.03, val_acc:0.95]
Epoch [41/100    avg_loss:0.03, val_acc:0.94]
Epoch [42/100    avg_loss:0.04, val_acc:0.95]
Epoch [43/100    avg_loss:0.05, val_acc:0.96]
Epoch [44/100    avg_loss:0.04, val_acc:0.95]
Epoch [45/100    avg_loss:0.04, val_acc:0.92]
Epoch [46/100    avg_loss:0.03, val_acc:0.93]
Epoch [47/100    avg_loss:0.03, val_acc:0.97]
Epoch [48/100    avg_loss:0.01, val_acc:0.96]
Epoch [49/100    avg_loss:0.01, val_acc:0.97]
Epoch [50/100    avg_loss:0.03, val_acc:0.95]
Epoch [51/100    avg_loss:0.01, val_acc:0.96]
Epoch [52/100    avg_loss:0.00, val_acc:0.96]
Epoch [53/100    avg_loss:0.00, val_acc:0.96]
Epoch [54/100    avg_loss:0.00, val_acc:0.97]
Epoch [55/100    avg_loss:0.00, val_acc:0.97]
Epoch [56/100    avg_loss:0.02, val_acc:0.96]
Epoch [57/100    avg_loss:0.03, val_acc:0.96]
Epoch [58/100    avg_loss:0.01, val_acc:0.95]
Epoch [59/100    avg_loss:0.04, val_acc:0.93]
Epoch [60/100    avg_loss:0.09, val_acc:0.95]
Epoch [61/100    avg_loss:0.07, val_acc:0.90]
Epoch [62/100    avg_loss:0.08, val_acc:0.93]
Epoch [63/100    avg_loss:0.08, val_acc:0.91]
Epoch [64/100    avg_loss:0.11, val_acc:0.94]
Epoch [65/100    avg_loss:0.02, val_acc:0.95]
Epoch [66/100    avg_loss:0.01, val_acc:0.96]
Epoch [67/100    avg_loss:0.00, val_acc:0.96]
Epoch [68/100    avg_loss:0.00, val_acc:0.97]
Epoch [69/100    avg_loss:0.00, val_acc:0.97]
Epoch [70/100    avg_loss:0.00, val_acc:0.97]
Epoch [71/100    avg_loss:0.00, val_acc:0.96]
Epoch [72/100    avg_loss:0.01, val_acc:0.96]
Epoch [73/100    avg_loss:0.02, val_acc:0.94]
Epoch [74/100    avg_loss:0.07, val_acc:0.94]
Epoch [75/100    avg_loss:0.04, val_acc:0.96]
Epoch [76/100    avg_loss:0.04, val_acc:0.94]
Epoch [77/100    avg_loss:0.04, val_acc:0.96]
Epoch [78/100    avg_loss:0.01, val_acc:0.96]
Epoch [79/100    avg_loss:0.00, val_acc:0.97]
Epoch [80/100    avg_loss:0.00, val_acc:0.97]
Epoch [81/100    avg_loss:0.01, val_acc:0.96]
Epoch [82/100    avg_loss:0.02, val_acc:0.95]
Epoch [83/100    avg_loss:0.06, val_acc:0.94]
Epoch [84/100    avg_loss:0.02, val_acc:0.96]
Epoch [85/100    avg_loss:0.03, val_acc:0.94]
Epoch [86/100    avg_loss:0.01, val_acc:0.97]
Epoch [87/100    avg_loss:0.02, val_acc:0.96]
Epoch [88/100    avg_loss:0.01, val_acc:0.97]
Epoch [89/100    avg_loss:0.03, val_acc:0.96]
Epoch [90/100    avg_loss:0.01, val_acc:0.97]
Epoch [91/100    avg_loss:0.01, val_acc:0.97]
Epoch [92/100    avg_loss:0.00, val_acc:0.97]
Epoch [93/100    avg_loss:0.00, val_acc:0.97]
Epoch [94/100    avg_loss:0.00, val_acc:0.95]
Epoch [95/100    avg_loss:0.06, val_acc:0.93]
Epoch [96/100    avg_loss:0.18, val_acc:0.92]
Epoch [97/100    avg_loss:0.07, val_acc:0.97]
Epoch [98/100    avg_loss:0.03, val_acc:0.95]
Epoch [99/100    avg_loss:0.02, val_acc:0.97]
Epoch [100/100    avg_loss:0.00, val_acc:0.97]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0   37    0    0    0    0    0    0    3    0    0    0    1    0
     0    0    0]
 [   0    0 1226    0    9    0    0    0    0    0   14   36    0    0
     0    0    0]
 [   0    0   19  645    0    0    2    0    0    0    3   51   26    0
     0    1    0]
 [   0    0    7    0  202    0    0    0    0    0    0    2    2    0
     0    0    0]
 [   0    0    3    0    0  428    0    1    0    0    0    0    0    0
     3    0    0]
 [   0    0    0    0    0    0  656    0    0    0    0    1    0    0
     0    0    0]
 [   0    0    0    0    0    1    0   24    0    0    0    0    0    0
     0    0    0]
 [   0    1    0    0    0    0    0    0  429    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    1    0    0   17    0    0    0    0
     0    0    0]
 [   0    0   18    0    0    0    0    0    0    0  774   82    1    0
     0    0    0]
 [   0    0   10    1    0    0    1    0    0    0   11 2180    5    0
     2    0    0]
 [   0    0    9    2    0    0    0    0    0    0    3   17  501    0
     0    0    2]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0  185
     0    0    0]
 [   0    0    0    0    0    0    1    0    0    0    0    0    0    0
  1125   13    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
   126  221    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    1    0
     0    0   83]]

Accuracy:
94.6667

F1 scores:
[   nan 0.9367 0.9515 0.9247 0.9528 0.9907 0.9954 0.96   0.9954 0.9714
 0.9214 0.9522 0.9356 1.     0.9395 0.7595 0.9822]

Kappa:
0.9389
IndianPines数据集的结果如下
['93.67+-0.0' '95.15+-0.0' '92.47+-0.0' '95.28+-0.0' '99.07+-0.0'
 '99.54+-0.0' '96.0+-0.0' '99.54+-0.0' '97.14+-0.0' '92.14+-0.0'
 '95.22+-0.0' '93.56+-0.0' '100.0+-0.0' '93.95+-0.0' '75.95+-0.0'
 '98.22+-0.0']
acc_dataset [[94.66666667]]
OAMean 94.67 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:18--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:200
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f70703a15d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/200    avg_loss:2.03, val_acc:0.39]
Epoch [2/200    avg_loss:1.56, val_acc:0.42]
Epoch [3/200    avg_loss:1.33, val_acc:0.57]
Epoch [4/200    avg_loss:1.13, val_acc:0.62]
Epoch [5/200    avg_loss:0.96, val_acc:0.67]
Epoch [6/200    avg_loss:0.77, val_acc:0.76]
Epoch [7/200    avg_loss:0.64, val_acc:0.77]
Epoch [8/200    avg_loss:0.51, val_acc:0.83]
Epoch [9/200    avg_loss:0.40, val_acc:0.86]
Epoch [10/200    avg_loss:0.27, val_acc:0.92]
Epoch [11/200    avg_loss:0.26, val_acc:0.84]
Epoch [12/200    avg_loss:0.22, val_acc:0.92]
Epoch [13/200    avg_loss:0.13, val_acc:0.93]
Epoch [14/200    avg_loss:0.13, val_acc:0.93]
Epoch [15/200    avg_loss:0.10, val_acc:0.92]
Epoch [16/200    avg_loss:0.15, val_acc:0.94]
Epoch [17/200    avg_loss:0.12, val_acc:0.86]
Epoch [18/200    avg_loss:0.14, val_acc:0.95]
Epoch [19/200    avg_loss:0.09, val_acc:0.95]
Epoch [20/200    avg_loss:0.09, val_acc:0.94]
Epoch [21/200    avg_loss:0.05, val_acc:0.96]
Epoch [22/200    avg_loss:0.02, val_acc:0.95]
Epoch [23/200    avg_loss:0.03, val_acc:0.96]
Epoch [24/200    avg_loss:0.06, val_acc:0.94]
Epoch [25/200    avg_loss:0.03, val_acc:0.95]
Epoch [26/200    avg_loss:0.01, val_acc:0.96]
Epoch [27/200    avg_loss:0.01, val_acc:0.96]
Epoch [28/200    avg_loss:0.01, val_acc:0.97]
Epoch [29/200    avg_loss:0.03, val_acc:0.96]
Epoch [30/200    avg_loss:0.04, val_acc:0.96]
Epoch [31/200    avg_loss:0.03, val_acc:0.96]
Epoch [32/200    avg_loss:0.03, val_acc:0.97]
Epoch [33/200    avg_loss:0.04, val_acc:0.96]
Epoch [34/200    avg_loss:0.04, val_acc:0.95]
Epoch [35/200    avg_loss:0.03, val_acc:0.94]
Epoch [36/200    avg_loss:0.04, val_acc:0.93]
Epoch [37/200    avg_loss:0.07, val_acc:0.92]
Epoch [38/200    avg_loss:0.12, val_acc:0.93]
Epoch [39/200    avg_loss:0.20, val_acc:0.94]
Epoch [40/200    avg_loss:0.07, val_acc:0.96]
Epoch [41/200    avg_loss:0.02, val_acc:0.95]
Epoch [42/200    avg_loss:0.04, val_acc:0.96]
Epoch [43/200    avg_loss:0.09, val_acc:0.95]
Epoch [44/200    avg_loss:0.06, val_acc:0.96]
Epoch [45/200    avg_loss:0.01, val_acc:0.96]
Epoch [46/200    avg_loss:0.01, val_acc:0.97]
Epoch [47/200    avg_loss:0.00, val_acc:0.97]
Epoch [48/200    avg_loss:0.00, val_acc:0.97]
Epoch [49/200    avg_loss:0.00, val_acc:0.96]
Epoch [50/200    avg_loss:0.00, val_acc:0.96]
Epoch [51/200    avg_loss:0.00, val_acc:0.97]
Epoch [52/200    avg_loss:0.00, val_acc:0.97]
Epoch [53/200    avg_loss:0.00, val_acc:0.98]
Epoch [54/200    avg_loss:0.00, val_acc:0.97]
Epoch [55/200    avg_loss:0.00, val_acc:0.98]
Epoch [56/200    avg_loss:0.00, val_acc:0.97]
Epoch [57/200    avg_loss:0.00, val_acc:0.97]
Epoch [58/200    avg_loss:0.00, val_acc:0.97]
Epoch [59/200    avg_loss:0.00, val_acc:0.97]
Epoch [60/200    avg_loss:0.00, val_acc:0.98]
Epoch [61/200    avg_loss:0.00, val_acc:0.98]
Epoch [62/200    avg_loss:0.00, val_acc:0.98]
Epoch [63/200    avg_loss:0.00, val_acc:0.98]
Epoch [64/200    avg_loss:0.00, val_acc:0.97]
Epoch [65/200    avg_loss:0.00, val_acc:0.97]
Epoch [66/200    avg_loss:0.04, val_acc:0.96]
Epoch [67/200    avg_loss:0.02, val_acc:0.96]
Epoch [68/200    avg_loss:0.04, val_acc:0.96]
Epoch [69/200    avg_loss:0.04, val_acc:0.94]
Epoch [70/200    avg_loss:0.09, val_acc:0.94]
Epoch [71/200    avg_loss:0.06, val_acc:0.94]
Epoch [72/200    avg_loss:0.07, val_acc:0.94]
Epoch [73/200    avg_loss:0.10, val_acc:0.93]
Epoch [74/200    avg_loss:0.12, val_acc:0.93]
Epoch [75/200    avg_loss:0.05, val_acc:0.94]
Epoch [76/200    avg_loss:0.04, val_acc:0.95]
Epoch [77/200    avg_loss:0.05, val_acc:0.96]
Epoch [78/200    avg_loss:0.04, val_acc:0.96]
Epoch [79/200    avg_loss:0.13, val_acc:0.94]
Epoch [80/200    avg_loss:0.15, val_acc:0.92]
Epoch [81/200    avg_loss:0.05, val_acc:0.96]
Epoch [82/200    avg_loss:0.04, val_acc:0.96]
Epoch [83/200    avg_loss:0.03, val_acc:0.93]
Epoch [84/200    avg_loss:0.03, val_acc:0.96]
Epoch [85/200    avg_loss:0.02, val_acc:0.97]
Epoch [86/200    avg_loss:0.01, val_acc:0.96]
Epoch [87/200    avg_loss:0.00, val_acc:0.97]
Epoch [88/200    avg_loss:0.01, val_acc:0.97]
Epoch [89/200    avg_loss:0.00, val_acc:0.96]
Epoch [90/200    avg_loss:0.00, val_acc:0.96]
Epoch [91/200    avg_loss:0.00, val_acc:0.97]
Epoch [92/200    avg_loss:0.00, val_acc:0.97]
Epoch [93/200    avg_loss:0.00, val_acc:0.97]
Epoch [94/200    avg_loss:0.00, val_acc:0.97]
Epoch [95/200    avg_loss:0.00, val_acc:0.97]
Epoch [96/200    avg_loss:0.00, val_acc:0.97]
Epoch [97/200    avg_loss:0.00, val_acc:0.96]
Epoch [98/200    avg_loss:0.00, val_acc:0.97]
Epoch [99/200    avg_loss:0.00, val_acc:0.97]
Epoch [100/200    avg_loss:0.00, val_acc:0.97]
Epoch [101/200    avg_loss:0.00, val_acc:0.97]
Epoch [102/200    avg_loss:0.00, val_acc:0.97]
Epoch [103/200    avg_loss:0.00, val_acc:0.98]
Epoch [104/200    avg_loss:0.00, val_acc:0.97]
Epoch [105/200    avg_loss:0.01, val_acc:0.96]
Epoch [106/200    avg_loss:0.00, val_acc:0.97]
Epoch [107/200    avg_loss:0.01, val_acc:0.94]
Epoch [108/200    avg_loss:0.51, val_acc:0.86]
Epoch [109/200    avg_loss:0.29, val_acc:0.92]
Epoch [110/200    avg_loss:0.22, val_acc:0.93]
Epoch [111/200    avg_loss:0.09, val_acc:0.92]
Epoch [112/200    avg_loss:0.07, val_acc:0.95]
Epoch [113/200    avg_loss:0.02, val_acc:0.96]
Epoch [114/200    avg_loss:0.01, val_acc:0.95]
Epoch [115/200    avg_loss:0.02, val_acc:0.94]
Epoch [116/200    avg_loss:0.02, val_acc:0.96]
Epoch [117/200    avg_loss:0.01, val_acc:0.96]
Epoch [118/200    avg_loss:0.00, val_acc:0.96]
Epoch [119/200    avg_loss:0.00, val_acc:0.96]
Epoch [120/200    avg_loss:0.00, val_acc:0.97]
Epoch [121/200    avg_loss:0.00, val_acc:0.97]
Epoch [122/200    avg_loss:0.00, val_acc:0.96]
Epoch [123/200    avg_loss:0.00, val_acc:0.97]
Epoch [124/200    avg_loss:0.00, val_acc:0.97]
Epoch [125/200    avg_loss:0.00, val_acc:0.97]
Epoch [126/200    avg_loss:0.00, val_acc:0.97]
Epoch [127/200    avg_loss:0.00, val_acc:0.96]
Epoch [128/200    avg_loss:0.00, val_acc:0.97]
Epoch [129/200    avg_loss:0.00, val_acc:0.97]
Epoch [130/200    avg_loss:0.00, val_acc:0.97]
Epoch [131/200    avg_loss:0.00, val_acc:0.97]
Epoch [132/200    avg_loss:0.00, val_acc:0.97]
Epoch [133/200    avg_loss:0.00, val_acc:0.97]
Epoch [134/200    avg_loss:0.00, val_acc:0.97]
Epoch [135/200    avg_loss:0.00, val_acc:0.97]
Epoch [136/200    avg_loss:0.00, val_acc:0.97]
Epoch [137/200    avg_loss:0.00, val_acc:0.97]
Epoch [138/200    avg_loss:0.00, val_acc:0.98]
Epoch [139/200    avg_loss:0.00, val_acc:0.97]
Epoch [140/200    avg_loss:0.00, val_acc:0.97]
Epoch [141/200    avg_loss:0.00, val_acc:0.97]
Epoch [142/200    avg_loss:0.00, val_acc:0.97]
Epoch [143/200    avg_loss:0.00, val_acc:0.98]
Epoch [144/200    avg_loss:0.00, val_acc:0.97]
Epoch [145/200    avg_loss:0.02, val_acc:0.94]
Epoch [146/200    avg_loss:0.10, val_acc:0.93]
Epoch [147/200    avg_loss:0.03, val_acc:0.96]
Epoch [148/200    avg_loss:0.00, val_acc:0.97]
Epoch [149/200    avg_loss:0.00, val_acc:0.96]
Epoch [150/200    avg_loss:0.01, val_acc:0.96]
Epoch [151/200    avg_loss:0.00, val_acc:0.97]
Epoch [152/200    avg_loss:0.01, val_acc:0.96]
Epoch [153/200    avg_loss:0.03, val_acc:0.97]
Epoch [154/200    avg_loss:0.01, val_acc:0.95]
Epoch [155/200    avg_loss:0.04, val_acc:0.95]
Epoch [156/200    avg_loss:0.04, val_acc:0.95]
Epoch [157/200    avg_loss:0.02, val_acc:0.95]
Epoch [158/200    avg_loss:0.06, val_acc:0.94]
Epoch [159/200    avg_loss:0.15, val_acc:0.92]
Epoch [160/200    avg_loss:0.22, val_acc:0.94]
Epoch [161/200    avg_loss:0.18, val_acc:0.94]
Epoch [162/200    avg_loss:0.03, val_acc:0.96]
Epoch [163/200    avg_loss:0.05, val_acc:0.94]
Epoch [164/200    avg_loss:0.06, val_acc:0.93]
Epoch [165/200    avg_loss:0.16, val_acc:0.91]
Epoch [166/200    avg_loss:0.08, val_acc:0.96]
Epoch [167/200    avg_loss:0.01, val_acc:0.96]
Epoch [168/200    avg_loss:0.01, val_acc:0.97]
Epoch [169/200    avg_loss:0.00, val_acc:0.96]
Epoch [170/200    avg_loss:0.00, val_acc:0.96]
Epoch [171/200    avg_loss:0.00, val_acc:0.96]
Epoch [172/200    avg_loss:0.00, val_acc:0.97]
Epoch [173/200    avg_loss:0.01, val_acc:0.97]
Epoch [174/200    avg_loss:0.01, val_acc:0.97]
Epoch [175/200    avg_loss:0.00, val_acc:0.97]
Epoch [176/200    avg_loss:0.00, val_acc:0.97]
Epoch [177/200    avg_loss:0.03, val_acc:0.94]
Epoch [178/200    avg_loss:0.04, val_acc:0.95]
Epoch [179/200    avg_loss:0.02, val_acc:0.94]
Epoch [180/200    avg_loss:0.00, val_acc:0.95]
Epoch [181/200    avg_loss:0.00, val_acc:0.97]
Epoch [182/200    avg_loss:0.00, val_acc:0.96]
Epoch [183/200    avg_loss:0.01, val_acc:0.97]
Epoch [184/200    avg_loss:0.00, val_acc:0.97]
Epoch [185/200    avg_loss:0.00, val_acc:0.96]
Epoch [186/200    avg_loss:0.00, val_acc:0.97]
Epoch [187/200    avg_loss:0.00, val_acc:0.97]
Epoch [188/200    avg_loss:0.00, val_acc:0.97]
Epoch [189/200    avg_loss:0.00, val_acc:0.97]
Epoch [190/200    avg_loss:0.00, val_acc:0.97]
Epoch [191/200    avg_loss:0.00, val_acc:0.97]
Epoch [192/200    avg_loss:0.00, val_acc:0.97]
Epoch [193/200    avg_loss:0.00, val_acc:0.96]
Epoch [194/200    avg_loss:0.00, val_acc:0.97]
Epoch [195/200    avg_loss:0.00, val_acc:0.97]
Epoch [196/200    avg_loss:0.00, val_acc:0.97]
Epoch [197/200    avg_loss:0.00, val_acc:0.97]
Epoch [198/200    avg_loss:0.00, val_acc:0.97]
Epoch [199/200    avg_loss:0.00, val_acc:0.97]
Epoch [200/200    avg_loss:0.03, val_acc:0.96]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0   36    4    0    0    0    0    0    0    0    0    1    0    0
     0    0    0]
 [   0    0 1186    3    9    0    0    0    0    0   24   45   18    0
     0    0    0]
 [   0    0    5  630   26    0    0    0    0    1    1   31   47    0
     0    6    0]
 [   0    0    6    0  205    0    0    0    0    0    0    0    1    0
     1    0    0]
 [   0    0    0    0    0  433    0    0    0    0    0    0    0    0
     2    0    0]
 [   0    2    0    0    4    1  643    0    0    0    0    0    0    0
     5    2    0]
 [   0    0    0    0    0    0    0   25    0    0    0    0    0    0
     0    0    0]
 [   0    8    6    0    0    0    0    0  413    0    0    0    3    0
     0    0    0]
 [   0    0    0    0    0    0    1    0    0   11    0    0    0    0
     0    6    0]
 [   0    0   19    2    0    0    1    0    4    0  790   53    2    0
     2    0    2]
 [   0    0   20    2    0    0    0    0    0    0    5 2159   19    0
     2    0    3]
 [   0    0    6    2    0    0    0    0    0    0    0   16  502    0
     0    4    4]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0  185
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
  1131    8    0]
 [   0    0    0    0    0    0    1    0    0    0    0    0    0    0
   142  201    3]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0   84]]

Accuracy:
93.5935

F1 scores:
[   nan 0.8276 0.935  0.9091 0.8972 0.9965 0.987  1.     0.9752 0.7333
 0.9322 0.9564 0.8917 1.     0.9332 0.7003 0.9333]

Kappa:
0.9268
IndianPines数据集的结果如下
['82.76+-0.0' '93.5+-0.0' '90.91+-0.0' '89.72+-0.0' '99.65+-0.0'
 '98.7+-0.0' '100.0+-0.0' '97.52+-0.0' '73.33+-0.0' '93.22+-0.0'
 '95.64+-0.0' '89.17+-0.0' '100.0+-0.0' '93.32+-0.0' '70.03+-0.0'
 '93.33+-0.0']
acc_dataset [[93.59349593]]
OAMean 93.59 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:24--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:25--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:200
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f470117e750>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/200    avg_loss:2.09, val_acc:0.35]
Epoch [2/200    avg_loss:1.62, val_acc:0.48]
Epoch [3/200    avg_loss:1.38, val_acc:0.55]
Epoch [4/200    avg_loss:1.22, val_acc:0.61]
Epoch [5/200    avg_loss:0.99, val_acc:0.70]
Epoch [6/200    avg_loss:0.83, val_acc:0.72]
Epoch [7/200    avg_loss:0.71, val_acc:0.76]
Epoch [8/200    avg_loss:0.56, val_acc:0.83]
Epoch [9/200    avg_loss:0.44, val_acc:0.84]
Epoch [10/200    avg_loss:0.34, val_acc:0.88]
Epoch [11/200    avg_loss:0.25, val_acc:0.89]
Epoch [12/200    avg_loss:0.30, val_acc:0.86]
Epoch [13/200    avg_loss:0.24, val_acc:0.91]
Epoch [14/200    avg_loss:0.15, val_acc:0.92]
Epoch [15/200    avg_loss:0.10, val_acc:0.94]
Epoch [16/200    avg_loss:0.07, val_acc:0.94]
Epoch [17/200    avg_loss:0.06, val_acc:0.95]
Epoch [18/200    avg_loss:0.07, val_acc:0.94]
Epoch [19/200    avg_loss:0.16, val_acc:0.92]
Epoch [20/200    avg_loss:0.11, val_acc:0.92]
Epoch [21/200    avg_loss:0.10, val_acc:0.95]
Epoch [22/200    avg_loss:0.05, val_acc:0.95]
Epoch [23/200    avg_loss:0.09, val_acc:0.93]
Epoch [24/200    avg_loss:0.06, val_acc:0.93]
Epoch [25/200    avg_loss:0.05, val_acc:0.94]
Epoch [26/200    avg_loss:0.03, val_acc:0.94]
Epoch [27/200    avg_loss:0.05, val_acc:0.95]
Epoch [28/200    avg_loss:0.01, val_acc:0.95]
Epoch [29/200    avg_loss:0.03, val_acc:0.93]
Epoch [30/200    avg_loss:0.05, val_acc:0.95]
Epoch [31/200    avg_loss:0.04, val_acc:0.93]
Epoch [32/200    avg_loss:0.09, val_acc:0.93]
Epoch [33/200    avg_loss:0.03, val_acc:0.94]
Epoch [34/200    avg_loss:0.01, val_acc:0.95]
Epoch [35/200    avg_loss:0.03, val_acc:0.93]
Epoch [36/200    avg_loss:0.10, val_acc:0.91]
Epoch [37/200    avg_loss:0.22, val_acc:0.91]
Epoch [38/200    avg_loss:0.15, val_acc:0.93]
Epoch [39/200    avg_loss:0.06, val_acc:0.94]
Epoch [40/200    avg_loss:0.03, val_acc:0.94]
Epoch [41/200    avg_loss:0.02, val_acc:0.95]
Epoch [42/200    avg_loss:0.01, val_acc:0.95]
Epoch [43/200    avg_loss:0.01, val_acc:0.95]
Epoch [44/200    avg_loss:0.01, val_acc:0.96]
Epoch [45/200    avg_loss:0.01, val_acc:0.95]
Epoch [46/200    avg_loss:0.00, val_acc:0.94]
Epoch [47/200    avg_loss:0.03, val_acc:0.96]
Epoch [48/200    avg_loss:0.00, val_acc:0.96]
Epoch [49/200    avg_loss:0.01, val_acc:0.95]
Epoch [50/200    avg_loss:0.02, val_acc:0.95]
Epoch [51/200    avg_loss:0.01, val_acc:0.96]
Epoch [52/200    avg_loss:0.03, val_acc:0.95]
Epoch [53/200    avg_loss:0.01, val_acc:0.95]
Epoch [54/200    avg_loss:0.02, val_acc:0.95]
Epoch [55/200    avg_loss:0.02, val_acc:0.95]
Epoch [56/200    avg_loss:0.01, val_acc:0.94]
Epoch [57/200    avg_loss:0.01, val_acc:0.94]
Epoch [58/200    avg_loss:0.03, val_acc:0.93]
Epoch [59/200    avg_loss:0.04, val_acc:0.94]
Epoch [60/200    avg_loss:0.07, val_acc:0.94]
Epoch [61/200    avg_loss:0.04, val_acc:0.93]
Epoch [62/200    avg_loss:0.06, val_acc:0.91]
Epoch [63/200    avg_loss:0.07, val_acc:0.94]
Epoch [64/200    avg_loss:0.15, val_acc:0.90]
Epoch [65/200    avg_loss:0.12, val_acc:0.92]
Epoch [66/200    avg_loss:0.04, val_acc:0.93]
Epoch [67/200    avg_loss:0.06, val_acc:0.94]
Epoch [68/200    avg_loss:0.03, val_acc:0.94]
Epoch [69/200    avg_loss:0.01, val_acc:0.96]
Epoch [70/200    avg_loss:0.01, val_acc:0.96]
Epoch [71/200    avg_loss:0.00, val_acc:0.96]
Epoch [72/200    avg_loss:0.00, val_acc:0.97]
Epoch [73/200    avg_loss:0.00, val_acc:0.96]
Epoch [74/200    avg_loss:0.02, val_acc:0.95]
Epoch [75/200    avg_loss:0.00, val_acc:0.96]
Epoch [76/200    avg_loss:0.03, val_acc:0.95]
Epoch [77/200    avg_loss:0.04, val_acc:0.95]
Epoch [78/200    avg_loss:0.04, val_acc:0.95]
Epoch [79/200    avg_loss:0.03, val_acc:0.95]
Epoch [80/200    avg_loss:0.04, val_acc:0.93]
Epoch [81/200    avg_loss:0.03, val_acc:0.94]
Epoch [82/200    avg_loss:0.01, val_acc:0.94]
Epoch [83/200    avg_loss:0.03, val_acc:0.96]
Epoch [84/200    avg_loss:0.05, val_acc:0.92]
Epoch [85/200    avg_loss:0.05, val_acc:0.93]
Epoch [86/200    avg_loss:0.02, val_acc:0.96]
Epoch [87/200    avg_loss:0.03, val_acc:0.94]
Epoch [88/200    avg_loss:0.08, val_acc:0.94]
Epoch [89/200    avg_loss:0.03, val_acc:0.94]
Epoch [90/200    avg_loss:0.07, val_acc:0.92]
Epoch [91/200    avg_loss:0.04, val_acc:0.95]
Epoch [92/200    avg_loss:0.05, val_acc:0.95]
Epoch [93/200    avg_loss:0.02, val_acc:0.95]
Epoch [94/200    avg_loss:0.00, val_acc:0.97]
Epoch [95/200    avg_loss:0.00, val_acc:0.96]
Epoch [96/200    avg_loss:0.00, val_acc:0.96]
Epoch [97/200    avg_loss:0.00, val_acc:0.97]
Epoch [98/200    avg_loss:0.00, val_acc:0.96]
Epoch [99/200    avg_loss:0.00, val_acc:0.96]
Epoch [100/200    avg_loss:0.00, val_acc:0.96]
Epoch [101/200    avg_loss:0.01, val_acc:0.95]
Epoch [102/200    avg_loss:0.01, val_acc:0.97]
Epoch [103/200    avg_loss:0.00, val_acc:0.97]
Epoch [104/200    avg_loss:0.00, val_acc:0.97]
Epoch [105/200    avg_loss:0.00, val_acc:0.97]
Epoch [106/200    avg_loss:0.00, val_acc:0.97]
Epoch [107/200    avg_loss:0.00, val_acc:0.97]
Epoch [108/200    avg_loss:0.00, val_acc:0.96]
Epoch [109/200    avg_loss:0.00, val_acc:0.96]
Epoch [110/200    avg_loss:0.00, val_acc:0.97]
Epoch [111/200    avg_loss:0.00, val_acc:0.97]
Epoch [112/200    avg_loss:0.01, val_acc:0.97]
Epoch [113/200    avg_loss:0.03, val_acc:0.93]
Epoch [114/200    avg_loss:0.10, val_acc:0.93]
Epoch [115/200    avg_loss:0.09, val_acc:0.93]
Epoch [116/200    avg_loss:0.11, val_acc:0.95]
Epoch [117/200    avg_loss:0.02, val_acc:0.96]
Epoch [118/200    avg_loss:0.03, val_acc:0.96]
Epoch [119/200    avg_loss:0.00, val_acc:0.97]
Epoch [120/200    avg_loss:0.01, val_acc:0.96]
Epoch [121/200    avg_loss:0.02, val_acc:0.96]
Epoch [122/200    avg_loss:0.05, val_acc:0.94]
Epoch [123/200    avg_loss:0.02, val_acc:0.94]
Epoch [124/200    avg_loss:0.00, val_acc:0.95]
Epoch [125/200    avg_loss:0.01, val_acc:0.94]
Epoch [126/200    avg_loss:0.00, val_acc:0.94]
Epoch [127/200    avg_loss:0.01, val_acc:0.94]
Epoch [128/200    avg_loss:0.07, val_acc:0.93]
Epoch [129/200    avg_loss:0.02, val_acc:0.93]
Epoch [130/200    avg_loss:0.00, val_acc:0.95]
Epoch [131/200    avg_loss:0.01, val_acc:0.94]
Epoch [132/200    avg_loss:0.01, val_acc:0.96]
Epoch [133/200    avg_loss:0.00, val_acc:0.96]
Epoch [134/200    avg_loss:0.00, val_acc:0.96]
Epoch [135/200    avg_loss:0.01, val_acc:0.96]
Epoch [136/200    avg_loss:0.01, val_acc:0.96]
Epoch [137/200    avg_loss:0.09, val_acc:0.94]
Epoch [138/200    avg_loss:0.05, val_acc:0.91]
Epoch [139/200    avg_loss:0.03, val_acc:0.95]
Epoch [140/200    avg_loss:0.01, val_acc:0.96]
Epoch [141/200    avg_loss:0.01, val_acc:0.96]
Epoch [142/200    avg_loss:0.02, val_acc:0.96]
Epoch [143/200    avg_loss:0.01, val_acc:0.96]
Epoch [144/200    avg_loss:0.00, val_acc:0.96]
Epoch [145/200    avg_loss:0.00, val_acc:0.96]
Epoch [146/200    avg_loss:0.00, val_acc:0.96]
Epoch [147/200    avg_loss:0.00, val_acc:0.97]
Epoch [148/200    avg_loss:0.00, val_acc:0.96]
Epoch [149/200    avg_loss:0.01, val_acc:0.95]
Epoch [150/200    avg_loss:0.02, val_acc:0.93]
Epoch [151/200    avg_loss:0.06, val_acc:0.93]
Epoch [152/200    avg_loss:0.04, val_acc:0.94]
Epoch [153/200    avg_loss:0.05, val_acc:0.94]
Epoch [154/200    avg_loss:0.02, val_acc:0.95]
Epoch [155/200    avg_loss:0.00, val_acc:0.96]
Epoch [156/200    avg_loss:0.00, val_acc:0.96]
Epoch [157/200    avg_loss:0.01, val_acc:0.95]
Epoch [158/200    avg_loss:0.00, val_acc:0.94]
Epoch [159/200    avg_loss:0.01, val_acc:0.96]
Epoch [160/200    avg_loss:0.00, val_acc:0.96]
Epoch [161/200    avg_loss:0.00, val_acc:0.96]
Epoch [162/200    avg_loss:0.02, val_acc:0.95]
Epoch [163/200    avg_loss:0.02, val_acc:0.94]
Epoch [164/200    avg_loss:0.03, val_acc:0.92]
Epoch [165/200    avg_loss:0.05, val_acc:0.94]
Epoch [166/200    avg_loss:0.04, val_acc:0.91]
Epoch [167/200    avg_loss:0.06, val_acc:0.94]
Epoch [168/200    avg_loss:0.16, val_acc:0.90]
Epoch [169/200    avg_loss:0.09, val_acc:0.92]
Epoch [170/200    avg_loss:0.12, val_acc:0.94]
Epoch [171/200    avg_loss:0.11, val_acc:0.91]
Epoch [172/200    avg_loss:0.03, val_acc:0.95]
Epoch [173/200    avg_loss:0.01, val_acc:0.95]
Epoch [174/200    avg_loss:0.00, val_acc:0.95]
Epoch [175/200    avg_loss:0.00, val_acc:0.95]
Epoch [176/200    avg_loss:0.00, val_acc:0.96]
Epoch [177/200    avg_loss:0.00, val_acc:0.96]
Epoch [178/200    avg_loss:0.00, val_acc:0.95]
Epoch [179/200    avg_loss:0.00, val_acc:0.96]
Epoch [180/200    avg_loss:0.00, val_acc:0.96]
Epoch [181/200    avg_loss:0.00, val_acc:0.96]
Epoch [182/200    avg_loss:0.00, val_acc:0.95]
Epoch [183/200    avg_loss:0.00, val_acc:0.96]
Epoch [184/200    avg_loss:0.00, val_acc:0.96]
Epoch [185/200    avg_loss:0.00, val_acc:0.97]
Epoch [186/200    avg_loss:0.00, val_acc:0.96]
Epoch [187/200    avg_loss:0.00, val_acc:0.97]
Epoch [188/200    avg_loss:0.00, val_acc:0.97]
Epoch [189/200    avg_loss:0.00, val_acc:0.96]
Epoch [190/200    avg_loss:0.00, val_acc:0.96]
Epoch [191/200    avg_loss:0.00, val_acc:0.96]
Epoch [192/200    avg_loss:0.00, val_acc:0.96]
Epoch [193/200    avg_loss:0.00, val_acc:0.96]
Epoch [194/200    avg_loss:0.00, val_acc:0.96]
Epoch [195/200    avg_loss:0.00, val_acc:0.96]
Epoch [196/200    avg_loss:0.00, val_acc:0.97]
Epoch [197/200    avg_loss:0.00, val_acc:0.96]
Epoch [198/200    avg_loss:0.00, val_acc:0.97]
Epoch [199/200    avg_loss:0.00, val_acc:0.97]
Epoch [200/200    avg_loss:0.00, val_acc:0.97]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0   41    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0    0 1253    4    0    0    0    0    0    0    6   19    3    0
     0    0    0]
 [   0    0   25  644    9    1    0    0    0    0    1   26   38    0
     0    3    0]
 [   0    0    0    7  200    0    0    0    0    0    0    1    4    0
     0    1    0]
 [   0    0    2    0    0  425    0    0    0    0    0    0    0    0
     8    0    0]
 [   0    0    0    0    0    0  654    0    0    0    0    0    0    0
     3    0    0]
 [   0    0    0    0    0    2    0   23    0    0    0    0    0    0
     0    0    0]
 [   0    2    0    0    0    1    0    0  427    0    0    0    0    0
     0    0    0]
 [   0    0    0    1    0    0   13    0    0    4    0    0    0    0
     0    0    0]
 [   0    0   32    6    0    0    0    0    0    0  753   82    0    2
     0    0    0]
 [   0    0   24    7    0    0    0    0    0    0    7 2159   13    0
     0    0    0]
 [   0    2    8    1    0    0    0    0    1    0    1   12  508    0
     0    1    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0  185
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
  1123   16    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
   121  226    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    2    0
     0    0   82]]

Accuracy:
94.3848

F1 scores:
[   nan 0.9535 0.9532 0.909  0.9479 0.9838 0.9879 0.9583 0.9953 0.3636
 0.9166 0.9576 0.922  0.9946 0.9382 0.7609 0.988 ]

Kappa:
0.9358
IndianPines数据集的结果如下
['95.35+-0.0' '95.32+-0.0' '90.9+-0.0' '94.79+-0.0' '98.38+-0.0'
 '98.79+-0.0' '95.83+-0.0' '99.53+-0.0' '36.36+-0.0' '91.66+-0.0'
 '95.76+-0.0' '92.2+-0.0' '99.46+-0.0' '93.82+-0.0' '76.09+-0.0'
 '98.8+-0.0']
acc_dataset [[94.38482385]]
OAMean 94.38 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:35--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:100
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fa6f57b4390>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/100    avg_loss:2.07, val_acc:0.41]
Epoch [2/100    avg_loss:1.61, val_acc:0.46]
Epoch [3/100    avg_loss:1.43, val_acc:0.53]
Epoch [4/100    avg_loss:1.18, val_acc:0.62]
Epoch [5/100    avg_loss:1.08, val_acc:0.58]
Epoch [6/100    avg_loss:0.94, val_acc:0.69]
Epoch [7/100    avg_loss:0.78, val_acc:0.76]
Epoch [8/100    avg_loss:0.58, val_acc:0.81]
Epoch [9/100    avg_loss:0.48, val_acc:0.82]
Epoch [10/100    avg_loss:0.36, val_acc:0.84]
Epoch [11/100    avg_loss:0.32, val_acc:0.88]
Epoch [12/100    avg_loss:0.30, val_acc:0.86]
Epoch [13/100    avg_loss:0.21, val_acc:0.91]
Epoch [14/100    avg_loss:0.16, val_acc:0.90]
Epoch [15/100    avg_loss:0.12, val_acc:0.89]
Epoch [16/100    avg_loss:0.11, val_acc:0.94]
Epoch [17/100    avg_loss:0.11, val_acc:0.89]
Epoch [18/100    avg_loss:0.08, val_acc:0.94]
Epoch [19/100    avg_loss:0.07, val_acc:0.92]
Epoch [20/100    avg_loss:0.09, val_acc:0.92]
Epoch [21/100    avg_loss:0.11, val_acc:0.92]
Epoch [22/100    avg_loss:0.06, val_acc:0.93]
Epoch [23/100    avg_loss:0.07, val_acc:0.89]
Epoch [24/100    avg_loss:0.09, val_acc:0.93]
Epoch [25/100    avg_loss:0.05, val_acc:0.93]
Epoch [26/100    avg_loss:0.04, val_acc:0.95]
Epoch [27/100    avg_loss:0.04, val_acc:0.95]
Epoch [28/100    avg_loss:0.04, val_acc:0.93]
Epoch [29/100    avg_loss:0.12, val_acc:0.92]
Epoch [30/100    avg_loss:0.10, val_acc:0.93]
Epoch [31/100    avg_loss:0.08, val_acc:0.94]
Epoch [32/100    avg_loss:0.03, val_acc:0.94]
Epoch [33/100    avg_loss:0.02, val_acc:0.95]
Epoch [34/100    avg_loss:0.01, val_acc:0.96]
Epoch [35/100    avg_loss:0.01, val_acc:0.97]
Epoch [36/100    avg_loss:0.00, val_acc:0.97]
Epoch [37/100    avg_loss:0.00, val_acc:0.96]
Epoch [38/100    avg_loss:0.03, val_acc:0.93]
Epoch [39/100    avg_loss:0.09, val_acc:0.92]
Epoch [40/100    avg_loss:0.02, val_acc:0.95]
Epoch [41/100    avg_loss:0.04, val_acc:0.95]
Epoch [42/100    avg_loss:0.04, val_acc:0.95]
Epoch [43/100    avg_loss:0.16, val_acc:0.88]
Epoch [44/100    avg_loss:0.10, val_acc:0.93]
Epoch [45/100    avg_loss:0.08, val_acc:0.94]
Epoch [46/100    avg_loss:0.03, val_acc:0.95]
Epoch [47/100    avg_loss:0.00, val_acc:0.95]
Epoch [48/100    avg_loss:0.03, val_acc:0.95]
Epoch [49/100    avg_loss:0.04, val_acc:0.87]
Epoch [50/100    avg_loss:0.11, val_acc:0.90]
Epoch [51/100    avg_loss:0.07, val_acc:0.94]
Epoch [52/100    avg_loss:0.03, val_acc:0.94]
Epoch [53/100    avg_loss:0.01, val_acc:0.96]
Epoch [54/100    avg_loss:0.00, val_acc:0.96]
Epoch [55/100    avg_loss:0.00, val_acc:0.97]
Epoch [56/100    avg_loss:0.00, val_acc:0.97]
Epoch [57/100    avg_loss:0.00, val_acc:0.97]
Epoch [58/100    avg_loss:0.00, val_acc:0.97]
Epoch [59/100    avg_loss:0.00, val_acc:0.96]
Epoch [60/100    avg_loss:0.00, val_acc:0.97]
Epoch [61/100    avg_loss:0.00, val_acc:0.97]
Epoch [62/100    avg_loss:0.00, val_acc:0.97]
Epoch [63/100    avg_loss:0.00, val_acc:0.97]
Epoch [64/100    avg_loss:0.00, val_acc:0.97]
Epoch [65/100    avg_loss:0.01, val_acc:0.97]
Epoch [66/100    avg_loss:0.01, val_acc:0.96]
Epoch [67/100    avg_loss:0.00, val_acc:0.97]
Epoch [68/100    avg_loss:0.00, val_acc:0.97]
Epoch [69/100    avg_loss:0.00, val_acc:0.96]
Epoch [70/100    avg_loss:0.00, val_acc:0.97]
Epoch [71/100    avg_loss:0.00, val_acc:0.97]
Epoch [72/100    avg_loss:0.00, val_acc:0.96]
Epoch [73/100    avg_loss:0.00, val_acc:0.97]
Epoch [74/100    avg_loss:0.00, val_acc:0.96]
Epoch [75/100    avg_loss:0.00, val_acc:0.96]
Epoch [76/100    avg_loss:0.00, val_acc:0.97]
Epoch [77/100    avg_loss:0.02, val_acc:0.95]
Epoch [78/100    avg_loss:0.10, val_acc:0.91]
Epoch [79/100    avg_loss:0.13, val_acc:0.93]
Epoch [80/100    avg_loss:0.23, val_acc:0.91]
Epoch [81/100    avg_loss:0.10, val_acc:0.92]
Epoch [82/100    avg_loss:0.03, val_acc:0.95]
Epoch [83/100    avg_loss:0.01, val_acc:0.96]
Epoch [84/100    avg_loss:0.02, val_acc:0.96]
Epoch [85/100    avg_loss:0.01, val_acc:0.96]
Epoch [86/100    avg_loss:0.00, val_acc:0.96]
Epoch [87/100    avg_loss:0.00, val_acc:0.96]
Epoch [88/100    avg_loss:0.00, val_acc:0.97]
Epoch [89/100    avg_loss:0.00, val_acc:0.96]
Epoch [90/100    avg_loss:0.00, val_acc:0.96]
Epoch [91/100    avg_loss:0.00, val_acc:0.97]
Epoch [92/100    avg_loss:0.00, val_acc:0.97]
Epoch [93/100    avg_loss:0.00, val_acc:0.97]
Epoch [94/100    avg_loss:0.00, val_acc:0.97]
Epoch [95/100    avg_loss:0.00, val_acc:0.96]
Epoch [96/100    avg_loss:0.01, val_acc:0.93]
Epoch [97/100    avg_loss:0.09, val_acc:0.88]
Epoch [98/100    avg_loss:0.11, val_acc:0.92]
Epoch [99/100    avg_loss:0.11, val_acc:0.92]
Epoch [100/100    avg_loss:0.01, val_acc:0.95]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0   37    2    0    0    0    0    0    2    0    0    0    0    0
     0    0    0]
 [   0    0 1203    4    4    0    0    0    0    0   23   43    8    0
     0    0    0]
 [   0    0   11  679    3    2    6    0    0    0    0   27   17    0
     1    1    0]
 [   0    0    0   19  192    0    0    0    1    0    0    0    0    1
     0    0    0]
 [   0    0    1    0    0  430    0    0    0    0    0    1    0    0
     3    0    0]
 [   0    0    0    0    0    2  649    0    0    0    0    0    0    5
     1    0    0]
 [   0    0    0    0    0    0    0   25    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0  430    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0   18    0    0    0    0
     0    0    0]
 [   0    0   18   15    0    0    0    0    0    1  797   42    1    0
     0    1    0]
 [   0    0   28   10    0    1    0    0    0    0    4 2158    9    0
     0    0    0]
 [   0    0   13    2    0    0    0    0    0    0    2   18  499    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    1    0  184
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    1    0    0    0    0
  1120   18    0]
 [   0    0    0    0    0    4    0    0    0    0    0    7    0    0
   133  203    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0   84]]

Accuracy:
94.3957

F1 scores:
[   nan 0.9487 0.9395 0.9201 0.932  0.984  0.9893 1.     0.9965 0.9474
 0.9371 0.9576 0.9345 0.9813 0.9345 0.7123 1.    ]

Kappa:
0.9359
IndianPines数据集的结果如下
['94.87+-0.0' '93.95+-0.0' '92.01+-0.0' '93.2+-0.0' '98.4+-0.0'
 '98.93+-0.0' '100.0+-0.0' '99.65+-0.0' '94.74+-0.0' '93.71+-0.0'
 '95.76+-0.0' '93.45+-0.0' '98.13+-0.0' '93.45+-0.0' '71.23+-0.0'
 '100.0+-0.0']
acc_dataset [[94.39566396]]
OAMean 94.40 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:45--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:100
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fe079954710>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/100    avg_loss:2.03, val_acc:0.35]
Epoch [2/100    avg_loss:1.60, val_acc:0.49]
Epoch [3/100    avg_loss:1.38, val_acc:0.57]
Epoch [4/100    avg_loss:1.16, val_acc:0.64]
Epoch [5/100    avg_loss:0.93, val_acc:0.66]
Epoch [6/100    avg_loss:0.79, val_acc:0.73]
Epoch [7/100    avg_loss:0.60, val_acc:0.73]
Epoch [8/100    avg_loss:0.51, val_acc:0.76]
Epoch [9/100    avg_loss:0.39, val_acc:0.85]
Epoch [10/100    avg_loss:0.26, val_acc:0.89]
Epoch [11/100    avg_loss:0.29, val_acc:0.82]
Epoch [12/100    avg_loss:0.24, val_acc:0.90]
Epoch [13/100    avg_loss:0.18, val_acc:0.87]
Epoch [14/100    avg_loss:0.15, val_acc:0.93]
Epoch [15/100    avg_loss:0.12, val_acc:0.92]
Epoch [16/100    avg_loss:0.05, val_acc:0.95]
Epoch [17/100    avg_loss:0.04, val_acc:0.95]
Epoch [18/100    avg_loss:0.05, val_acc:0.94]
Epoch [19/100    avg_loss:0.10, val_acc:0.93]
Epoch [20/100    avg_loss:0.07, val_acc:0.92]
Epoch [21/100    avg_loss:0.05, val_acc:0.93]
Epoch [22/100    avg_loss:0.05, val_acc:0.95]
Epoch [23/100    avg_loss:0.10, val_acc:0.96]
Epoch [24/100    avg_loss:0.10, val_acc:0.94]
Epoch [25/100    avg_loss:0.04, val_acc:0.95]
Epoch [26/100    avg_loss:0.03, val_acc:0.95]
Epoch [27/100    avg_loss:0.02, val_acc:0.96]
Epoch [28/100    avg_loss:0.02, val_acc:0.96]
Epoch [29/100    avg_loss:0.05, val_acc:0.94]
Epoch [30/100    avg_loss:0.05, val_acc:0.93]
Epoch [31/100    avg_loss:0.07, val_acc:0.94]
Epoch [32/100    avg_loss:0.05, val_acc:0.95]
Epoch [33/100    avg_loss:0.02, val_acc:0.97]
Epoch [34/100    avg_loss:0.01, val_acc:0.96]
Epoch [35/100    avg_loss:0.01, val_acc:0.93]
Epoch [36/100    avg_loss:0.01, val_acc:0.96]
Epoch [37/100    avg_loss:0.01, val_acc:0.98]
Epoch [38/100    avg_loss:0.00, val_acc:0.97]
Epoch [39/100    avg_loss:0.00, val_acc:0.97]
Epoch [40/100    avg_loss:0.01, val_acc:0.97]
Epoch [41/100    avg_loss:0.01, val_acc:0.97]
Epoch [42/100    avg_loss:0.00, val_acc:0.98]
Epoch [43/100    avg_loss:0.00, val_acc:0.98]
Epoch [44/100    avg_loss:0.00, val_acc:0.98]
Epoch [45/100    avg_loss:0.00, val_acc:0.98]
Epoch [46/100    avg_loss:0.00, val_acc:0.98]
Epoch [47/100    avg_loss:0.01, val_acc:0.97]
Epoch [48/100    avg_loss:0.05, val_acc:0.93]
Epoch [49/100    avg_loss:0.27, val_acc:0.79]
Epoch [50/100    avg_loss:0.22, val_acc:0.94]
Epoch [51/100    avg_loss:0.07, val_acc:0.95]
Epoch [52/100    avg_loss:0.12, val_acc:0.92]
Epoch [53/100    avg_loss:0.07, val_acc:0.96]
Epoch [54/100    avg_loss:0.02, val_acc:0.97]
Epoch [55/100    avg_loss:0.02, val_acc:0.95]
Epoch [56/100    avg_loss:0.01, val_acc:0.95]
Epoch [57/100    avg_loss:0.00, val_acc:0.96]
Epoch [58/100    avg_loss:0.00, val_acc:0.98]
Epoch [59/100    avg_loss:0.01, val_acc:0.95]
Epoch [60/100    avg_loss:0.02, val_acc:0.95]
Epoch [61/100    avg_loss:0.01, val_acc:0.96]
Epoch [62/100    avg_loss:0.01, val_acc:0.95]
Epoch [63/100    avg_loss:0.01, val_acc:0.96]
Epoch [64/100    avg_loss:0.01, val_acc:0.95]
Epoch [65/100    avg_loss:0.02, val_acc:0.95]
Epoch [66/100    avg_loss:0.03, val_acc:0.96]
Epoch [67/100    avg_loss:0.07, val_acc:0.95]
Epoch [68/100    avg_loss:0.03, val_acc:0.95]
Epoch [69/100    avg_loss:0.03, val_acc:0.96]
Epoch [70/100    avg_loss:0.02, val_acc:0.96]
Epoch [71/100    avg_loss:0.03, val_acc:0.94]
Epoch [72/100    avg_loss:0.03, val_acc:0.94]
Epoch [73/100    avg_loss:0.04, val_acc:0.95]
Epoch [74/100    avg_loss:0.02, val_acc:0.97]
Epoch [75/100    avg_loss:0.01, val_acc:0.97]
Epoch [76/100    avg_loss:0.00, val_acc:0.96]
Epoch [77/100    avg_loss:0.00, val_acc:0.98]
Epoch [78/100    avg_loss:0.00, val_acc:0.98]
Epoch [79/100    avg_loss:0.00, val_acc:0.98]
Epoch [80/100    avg_loss:0.00, val_acc:0.98]
Epoch [81/100    avg_loss:0.00, val_acc:0.98]
Epoch [82/100    avg_loss:0.00, val_acc:0.98]
Epoch [83/100    avg_loss:0.00, val_acc:0.98]
Epoch [84/100    avg_loss:0.00, val_acc:0.98]
Epoch [85/100    avg_loss:0.00, val_acc:0.98]
Epoch [86/100    avg_loss:0.00, val_acc:0.98]
Epoch [87/100    avg_loss:0.00, val_acc:0.98]
Epoch [88/100    avg_loss:0.01, val_acc:0.97]
Epoch [89/100    avg_loss:0.00, val_acc:0.98]
Epoch [90/100    avg_loss:0.00, val_acc:0.98]
Epoch [91/100    avg_loss:0.00, val_acc:0.97]
Epoch [92/100    avg_loss:0.00, val_acc:0.98]
Epoch [93/100    avg_loss:0.00, val_acc:0.97]
Epoch [94/100    avg_loss:0.00, val_acc:0.96]
Epoch [95/100    avg_loss:0.02, val_acc:0.94]
Epoch [96/100    avg_loss:0.03, val_acc:0.95]
Epoch [97/100    avg_loss:0.11, val_acc:0.93]
Epoch [98/100    avg_loss:0.09, val_acc:0.96]
Epoch [99/100    avg_loss:0.11, val_acc:0.94]
Epoch [100/100    avg_loss:0.05, val_acc:0.96]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0   27    1    0    0    0    0    0   13    0    0    0    0    0
     0    0    0]
 [   0    0 1258    1    0    0    0    0    0    0    7   16    3    0
     0    0    0]
 [   0    0    2  683    0    0    0    0    0    2    5   19   36    0
     0    0    0]
 [   0    0    6   43  162    0    0    0    1    0    0    0    1    0
     0    0    0]
 [   0    0    9    0    0  422    0    0    0    0    0    0    0    0
     4    0    0]
 [   0    0    0    0    0    0  649    0    0    0    0    2    0    0
     6    0    0]
 [   0    0    0    0    0    0    0   25    0    0    0    0    0    0
     0    0    0]
 [   0    0    2    0    0    0    0    0  428    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0   18    0    0    0    0
     0    0    0]
 [   0    0   12   14    0    0    0    0    0    0  835   11    3    0
     0    0    0]
 [   0    0   37    9    0    0    0    2    0    0   53 2058   44    0
     1    0    6]
 [   0    0   37    6    0    0    0    0    0    0   23    6  459    0
     0    1    2]
 [   0    0    0    0    0    0    0    0    0    0    0    1    0  184
     0    0    0]
 [   0    0    0    1    0    1    0    0    0    0    0    0    0    0
  1124   13    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
    77  269    1]
 [   0    0    0    0    0    0    0    0    0    0    7    0    0    0
     0    0   77]]

Accuracy:
94.0705

F1 scores:
[   nan 0.7941 0.9498 0.9082 0.864  0.9837 0.9939 0.9615 0.9817 0.9474
 0.9252 0.9521 0.85   0.9973 0.9562 0.854  0.9059]

Kappa:
0.9324
IndianPines数据集的结果如下
['79.41+-0.0' '94.98+-0.0' '90.82+-0.0' '86.4+-0.0' '98.37+-0.0'
 '99.39+-0.0' '96.15+-0.0' '98.17+-0.0' '94.74+-0.0' '92.52+-0.0'
 '95.21+-0.0' '85.0+-0.0' '99.73+-0.0' '95.62+-0.0' '85.4+-0.0'
 '90.59+-0.0']
acc_dataset [[94.0704607]]
OAMean 94.07 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:47--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:200
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f80352b2e10>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/200    avg_loss:2.10, val_acc:0.39]
Epoch [2/200    avg_loss:1.58, val_acc:0.50]
Epoch [3/200    avg_loss:1.29, val_acc:0.58]
Epoch [4/200    avg_loss:1.08, val_acc:0.66]
Epoch [5/200    avg_loss:0.92, val_acc:0.69]
Epoch [6/200    avg_loss:0.73, val_acc:0.71]
Epoch [7/200    avg_loss:0.63, val_acc:0.76]
Epoch [8/200    avg_loss:0.51, val_acc:0.79]
Epoch [9/200    avg_loss:0.39, val_acc:0.81]
Epoch [10/200    avg_loss:0.30, val_acc:0.85]
Epoch [11/200    avg_loss:0.28, val_acc:0.86]
Epoch [12/200    avg_loss:0.20, val_acc:0.88]
Epoch [13/200    avg_loss:0.12, val_acc:0.88]
Epoch [14/200    avg_loss:0.20, val_acc:0.85]
Epoch [15/200    avg_loss:0.22, val_acc:0.86]
Epoch [16/200    avg_loss:0.13, val_acc:0.91]
Epoch [17/200    avg_loss:0.11, val_acc:0.90]
Epoch [18/200    avg_loss:0.10, val_acc:0.91]
Epoch [19/200    avg_loss:0.07, val_acc:0.93]
Epoch [20/200    avg_loss:0.05, val_acc:0.95]
Epoch [21/200    avg_loss:0.04, val_acc:0.94]
Epoch [22/200    avg_loss:0.03, val_acc:0.93]
Epoch [23/200    avg_loss:0.03, val_acc:0.93]
Epoch [24/200    avg_loss:0.03, val_acc:0.94]
Epoch [25/200    avg_loss:0.04, val_acc:0.94]
Epoch [26/200    avg_loss:0.02, val_acc:0.94]
Epoch [27/200    avg_loss:0.01, val_acc:0.93]
Epoch [28/200    avg_loss:0.01, val_acc:0.95]
Epoch [29/200    avg_loss:0.02, val_acc:0.93]
Epoch [30/200    avg_loss:0.05, val_acc:0.90]
Epoch [31/200    avg_loss:0.05, val_acc:0.90]
Epoch [32/200    avg_loss:0.05, val_acc:0.93]
Epoch [33/200    avg_loss:0.06, val_acc:0.90]
Epoch [34/200    avg_loss:0.08, val_acc:0.94]
Epoch [35/200    avg_loss:0.04, val_acc:0.93]
Epoch [36/200    avg_loss:0.02, val_acc:0.93]
Epoch [37/200    avg_loss:0.02, val_acc:0.94]
Epoch [38/200    avg_loss:0.01, val_acc:0.94]
Epoch [39/200    avg_loss:0.01, val_acc:0.95]
Epoch [40/200    avg_loss:0.02, val_acc:0.93]
Epoch [41/200    avg_loss:0.05, val_acc:0.93]
Epoch [42/200    avg_loss:0.02, val_acc:0.95]
Epoch [43/200    avg_loss:0.03, val_acc:0.94]
Epoch [44/200    avg_loss:0.01, val_acc:0.95]
Epoch [45/200    avg_loss:0.02, val_acc:0.94]
Epoch [46/200    avg_loss:0.05, val_acc:0.92]
Epoch [47/200    avg_loss:0.14, val_acc:0.89]
Epoch [48/200    avg_loss:0.13, val_acc:0.92]
Epoch [49/200    avg_loss:0.08, val_acc:0.92]
Epoch [50/200    avg_loss:0.09, val_acc:0.93]
Epoch [51/200    avg_loss:0.10, val_acc:0.90]
Epoch [52/200    avg_loss:0.08, val_acc:0.94]
Epoch [53/200    avg_loss:0.02, val_acc:0.95]
Epoch [54/200    avg_loss:0.01, val_acc:0.95]
Epoch [55/200    avg_loss:0.00, val_acc:0.95]
Epoch [56/200    avg_loss:0.03, val_acc:0.92]
Epoch [57/200    avg_loss:0.01, val_acc:0.95]
Epoch [58/200    avg_loss:0.00, val_acc:0.96]
Epoch [59/200    avg_loss:0.00, val_acc:0.96]
Epoch [60/200    avg_loss:0.00, val_acc:0.95]
Epoch [61/200    avg_loss:0.00, val_acc:0.96]
Epoch [62/200    avg_loss:0.00, val_acc:0.96]
Epoch [63/200    avg_loss:0.00, val_acc:0.96]
Epoch [64/200    avg_loss:0.00, val_acc:0.95]
Epoch [65/200    avg_loss:0.00, val_acc:0.96]
Epoch [66/200    avg_loss:0.00, val_acc:0.96]
Epoch [67/200    avg_loss:0.00, val_acc:0.96]
Epoch [68/200    avg_loss:0.00, val_acc:0.96]
Epoch [69/200    avg_loss:0.00, val_acc:0.96]
Epoch [70/200    avg_loss:0.00, val_acc:0.96]
Epoch [71/200    avg_loss:0.00, val_acc:0.96]
Epoch [72/200    avg_loss:0.00, val_acc:0.96]
Epoch [73/200    avg_loss:0.00, val_acc:0.96]
Epoch [74/200    avg_loss:0.00, val_acc:0.96]
Epoch [75/200    avg_loss:0.00, val_acc:0.95]
Epoch [76/200    avg_loss:0.00, val_acc:0.95]
Epoch [77/200    avg_loss:0.00, val_acc:0.95]
Epoch [78/200    avg_loss:0.00, val_acc:0.96]
Epoch [79/200    avg_loss:0.00, val_acc:0.96]
Epoch [80/200    avg_loss:0.00, val_acc:0.95]
Epoch [81/200    avg_loss:0.00, val_acc:0.95]
Epoch [82/200    avg_loss:0.00, val_acc:0.96]
Epoch [83/200    avg_loss:0.00, val_acc:0.96]
Epoch [84/200    avg_loss:0.00, val_acc:0.95]
Epoch [85/200    avg_loss:0.00, val_acc:0.95]
Epoch [86/200    avg_loss:0.00, val_acc:0.95]
Epoch [87/200    avg_loss:0.00, val_acc:0.95]
Epoch [88/200    avg_loss:0.00, val_acc:0.96]
Epoch [89/200    avg_loss:0.00, val_acc:0.95]
Epoch [90/200    avg_loss:0.00, val_acc:0.96]
Epoch [91/200    avg_loss:0.00, val_acc:0.96]
Epoch [92/200    avg_loss:0.01, val_acc:0.93]
Epoch [93/200    avg_loss:0.14, val_acc:0.91]
Epoch [94/200    avg_loss:0.30, val_acc:0.86]
Epoch [95/200    avg_loss:0.23, val_acc:0.90]
Epoch [96/200    avg_loss:0.06, val_acc:0.93]
Epoch [97/200    avg_loss:0.02, val_acc:0.94]
Epoch [98/200    avg_loss:0.01, val_acc:0.95]
Epoch [99/200    avg_loss:0.02, val_acc:0.95]
Epoch [100/200    avg_loss:0.01, val_acc:0.94]
Epoch [101/200    avg_loss:0.05, val_acc:0.93]
Epoch [102/200    avg_loss:0.07, val_acc:0.91]
Epoch [103/200    avg_loss:0.07, val_acc:0.92]
Epoch [104/200    avg_loss:0.03, val_acc:0.94]
Epoch [105/200    avg_loss:0.01, val_acc:0.94]
Epoch [106/200    avg_loss:0.01, val_acc:0.93]
Epoch [107/200    avg_loss:0.03, val_acc:0.95]
Epoch [108/200    avg_loss:0.08, val_acc:0.93]
Epoch [109/200    avg_loss:0.04, val_acc:0.94]
Epoch [110/200    avg_loss:0.02, val_acc:0.94]
Epoch [111/200    avg_loss:0.03, val_acc:0.94]
Epoch [112/200    avg_loss:0.04, val_acc:0.95]
Epoch [113/200    avg_loss:0.01, val_acc:0.94]
Epoch [114/200    avg_loss:0.00, val_acc:0.94]
Epoch [115/200    avg_loss:0.00, val_acc:0.95]
Epoch [116/200    avg_loss:0.00, val_acc:0.95]
Epoch [117/200    avg_loss:0.00, val_acc:0.95]
Epoch [118/200    avg_loss:0.00, val_acc:0.95]
Epoch [119/200    avg_loss:0.00, val_acc:0.95]
Epoch [120/200    avg_loss:0.00, val_acc:0.95]
Epoch [121/200    avg_loss:0.00, val_acc:0.96]
Epoch [122/200    avg_loss:0.00, val_acc:0.95]
Epoch [123/200    avg_loss:0.00, val_acc:0.95]
Epoch [124/200    avg_loss:0.00, val_acc:0.95]
Epoch [125/200    avg_loss:0.00, val_acc:0.95]
Epoch [126/200    avg_loss:0.00, val_acc:0.95]
Epoch [127/200    avg_loss:0.00, val_acc:0.95]
Epoch [128/200    avg_loss:0.00, val_acc:0.95]
Epoch [129/200    avg_loss:0.00, val_acc:0.96]
Epoch [130/200    avg_loss:0.00, val_acc:0.95]
Epoch [131/200    avg_loss:0.00, val_acc:0.95]
Epoch [132/200    avg_loss:0.00, val_acc:0.95]
Epoch [133/200    avg_loss:0.00, val_acc:0.95]
Epoch [134/200    avg_loss:0.00, val_acc:0.95]
Epoch [135/200    avg_loss:0.00, val_acc:0.96]
Epoch [136/200    avg_loss:0.00, val_acc:0.96]
Epoch [137/200    avg_loss:0.00, val_acc:0.96]
Epoch [138/200    avg_loss:0.00, val_acc:0.96]
Epoch [139/200    avg_loss:0.00, val_acc:0.96]
Epoch [140/200    avg_loss:0.00, val_acc:0.95]
Epoch [141/200    avg_loss:0.00, val_acc:0.96]
Epoch [142/200    avg_loss:0.00, val_acc:0.95]
Epoch [143/200    avg_loss:0.00, val_acc:0.95]
Epoch [144/200    avg_loss:0.00, val_acc:0.96]
Epoch [145/200    avg_loss:0.00, val_acc:0.96]
Epoch [146/200    avg_loss:0.00, val_acc:0.96]
Epoch [147/200    avg_loss:0.00, val_acc:0.96]
Epoch [148/200    avg_loss:0.00, val_acc:0.96]
Epoch [149/200    avg_loss:0.00, val_acc:0.96]
Epoch [150/200    avg_loss:0.00, val_acc:0.96]
Epoch [151/200    avg_loss:0.00, val_acc:0.95]
Epoch [152/200    avg_loss:0.00, val_acc:0.96]
Epoch [153/200    avg_loss:0.00, val_acc:0.96]
Epoch [154/200    avg_loss:0.00, val_acc:0.95]
Epoch [155/200    avg_loss:0.00, val_acc:0.96]
Epoch [156/200    avg_loss:0.00, val_acc:0.96]
Epoch [157/200    avg_loss:0.00, val_acc:0.95]
Epoch [158/200    avg_loss:0.00, val_acc:0.95]
Epoch [159/200    avg_loss:0.00, val_acc:0.96]
Epoch [160/200    avg_loss:0.00, val_acc:0.95]
Epoch [161/200    avg_loss:0.00, val_acc:0.95]
Epoch [162/200    avg_loss:0.00, val_acc:0.95]
Epoch [163/200    avg_loss:0.06, val_acc:0.89]
Epoch [164/200    avg_loss:0.27, val_acc:0.81]
Epoch [165/200    avg_loss:0.28, val_acc:0.90]
Epoch [166/200    avg_loss:0.13, val_acc:0.92]
Epoch [167/200    avg_loss:0.09, val_acc:0.93]
Epoch [168/200    avg_loss:0.08, val_acc:0.93]
Epoch [169/200    avg_loss:0.04, val_acc:0.95]
Epoch [170/200    avg_loss:0.01, val_acc:0.95]
Epoch [171/200    avg_loss:0.00, val_acc:0.95]
Epoch [172/200    avg_loss:0.00, val_acc:0.95]
Epoch [173/200    avg_loss:0.00, val_acc:0.95]
Epoch [174/200    avg_loss:0.00, val_acc:0.95]
Epoch [175/200    avg_loss:0.00, val_acc:0.95]
Epoch [176/200    avg_loss:0.00, val_acc:0.95]
Epoch [177/200    avg_loss:0.00, val_acc:0.94]
Epoch [178/200    avg_loss:0.00, val_acc:0.94]
Epoch [179/200    avg_loss:0.00, val_acc:0.95]
Epoch [180/200    avg_loss:0.00, val_acc:0.96]
Epoch [181/200    avg_loss:0.00, val_acc:0.96]
Epoch [182/200    avg_loss:0.00, val_acc:0.96]
Epoch [183/200    avg_loss:0.00, val_acc:0.96]
Epoch [184/200    avg_loss:0.01, val_acc:0.95]
Epoch [185/200    avg_loss:0.00, val_acc:0.95]
Epoch [186/200    avg_loss:0.00, val_acc:0.96]
Epoch [187/200    avg_loss:0.00, val_acc:0.96]
Epoch [188/200    avg_loss:0.00, val_acc:0.96]
Epoch [189/200    avg_loss:0.00, val_acc:0.95]
Epoch [190/200    avg_loss:0.00, val_acc:0.96]
Epoch [191/200    avg_loss:0.00, val_acc:0.96]
Epoch [192/200    avg_loss:0.00, val_acc:0.96]
Epoch [193/200    avg_loss:0.00, val_acc:0.96]
Epoch [194/200    avg_loss:0.00, val_acc:0.95]
Epoch [195/200    avg_loss:0.00, val_acc:0.95]
Epoch [196/200    avg_loss:0.00, val_acc:0.95]
Epoch [197/200    avg_loss:0.02, val_acc:0.94]
Epoch [198/200    avg_loss:0.11, val_acc:0.91]
Epoch [199/200    avg_loss:0.05, val_acc:0.92]
Epoch [200/200    avg_loss:0.04, val_acc:0.93]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0   37    0    0    0    0    0    0    0    0    4    0    0    0
     0    0    0]
 [   0    0 1112   22    0    3    0    0    0    0   65   58   21    0
     2    1    1]
 [   0    0   23  618    2    0    0    0    0    0   23   18   62    0
     1    0    0]
 [   0    0    0   14  192    0    0    0    0    0    1    0    6    0
     0    0    0]
 [   0    0    0    0    0  429    0    0    0    0    0    2    0    0
     4    0    0]
 [   0    0    0    0    0    0  654    0    0    0    0    0    0    0
     3    0    0]
 [   0    0    0    0    0    0    0   25    0    0    0    0    0    0
     0    0    0]
 [   0   23    0    0    0    2    0    0  405    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0   17    0    0    0    0
     0    1    0]
 [   0    0   13    4    0    0    0    0    0    0  804   51    0    0
     2    1    0]
 [   0    0    9    6    0    1    0    0    0    0   95 2090    4    0
     4    1    0]
 [   0    0    0    5    0    0    0    0    0    0   35   32  456    0
     0    3    3]
 [   0    0    0    0    0    0    0    0    0    0    0    1    0  184
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    2    0    0    0    0
  1122   15    0]
 [   0    0    0    0    0    3    0    0    0    4    0    0    0    0
   113  226    1]
 [   0    0    0    0    0    0    0    0    0    0   13    1    0    0
     0    0   70]]

Accuracy:
91.5014

F1 scores:
[   nan 0.7327 0.9107 0.8729 0.9435 0.9828 0.9977 1.     0.9701 0.8293
 0.8397 0.9366 0.8421 0.9973 0.9389 0.7597 0.8805]

Kappa:
0.9030
IndianPines数据集的结果如下
['73.27+-0.0' '91.07+-0.0' '87.29+-0.0' '94.35+-0.0' '98.28+-0.0'
 '99.77+-0.0' '100.0+-0.0' '97.01+-0.0' '82.93+-0.0' '83.97+-0.0'
 '93.66+-0.0' '84.21+-0.0' '99.73+-0.0' '93.89+-0.0' '75.97+-0.0'
 '88.05+-0.0']
acc_dataset [[91.50135501]]
OAMean 91.50 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:50--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:100
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f143e4755d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/100    avg_loss:1.98, val_acc:0.40]
Epoch [2/100    avg_loss:1.53, val_acc:0.47]
Epoch [3/100    avg_loss:1.28, val_acc:0.59]
Epoch [4/100    avg_loss:1.08, val_acc:0.65]
Epoch [5/100    avg_loss:0.88, val_acc:0.69]
Epoch [6/100    avg_loss:0.75, val_acc:0.73]
Epoch [7/100    avg_loss:0.61, val_acc:0.75]
Epoch [8/100    avg_loss:0.52, val_acc:0.79]
Epoch [9/100    avg_loss:0.42, val_acc:0.83]
Epoch [10/100    avg_loss:0.30, val_acc:0.84]
Epoch [11/100    avg_loss:0.25, val_acc:0.87]
Epoch [12/100    avg_loss:0.27, val_acc:0.88]
Epoch [13/100    avg_loss:0.14, val_acc:0.92]
Epoch [14/100    avg_loss:0.13, val_acc:0.91]
Epoch [15/100    avg_loss:0.08, val_acc:0.89]
Epoch [16/100    avg_loss:0.15, val_acc:0.90]
Epoch [17/100    avg_loss:0.19, val_acc:0.90]
Epoch [18/100    avg_loss:0.15, val_acc:0.91]
Epoch [19/100    avg_loss:0.08, val_acc:0.91]
Epoch [20/100    avg_loss:0.06, val_acc:0.91]
Epoch [21/100    avg_loss:0.07, val_acc:0.93]
Epoch [22/100    avg_loss:0.09, val_acc:0.92]
Epoch [23/100    avg_loss:0.08, val_acc:0.94]
Epoch [24/100    avg_loss:0.06, val_acc:0.95]
Epoch [25/100    avg_loss:0.07, val_acc:0.94]
Epoch [26/100    avg_loss:0.04, val_acc:0.95]
Epoch [27/100    avg_loss:0.03, val_acc:0.95]
Epoch [28/100    avg_loss:0.02, val_acc:0.95]
Epoch [29/100    avg_loss:0.02, val_acc:0.95]
Epoch [30/100    avg_loss:0.01, val_acc:0.94]
Epoch [31/100    avg_loss:0.02, val_acc:0.93]
Epoch [32/100    avg_loss:0.04, val_acc:0.93]
Epoch [33/100    avg_loss:0.04, val_acc:0.94]
Epoch [34/100    avg_loss:0.02, val_acc:0.95]
Epoch [35/100    avg_loss:0.04, val_acc:0.95]
Epoch [36/100    avg_loss:0.03, val_acc:0.94]
Epoch [37/100    avg_loss:0.06, val_acc:0.95]
Epoch [38/100    avg_loss:0.07, val_acc:0.94]
Epoch [39/100    avg_loss:0.03, val_acc:0.93]
Epoch [40/100    avg_loss:0.02, val_acc:0.94]
Epoch [41/100    avg_loss:0.04, val_acc:0.94]
Epoch [42/100    avg_loss:0.02, val_acc:0.94]
Epoch [43/100    avg_loss:0.01, val_acc:0.94]
Epoch [44/100    avg_loss:0.00, val_acc:0.95]
Epoch [45/100    avg_loss:0.00, val_acc:0.97]
Epoch [46/100    avg_loss:0.00, val_acc:0.97]
Epoch [47/100    avg_loss:0.00, val_acc:0.96]
Epoch [48/100    avg_loss:0.00, val_acc:0.96]
Epoch [49/100    avg_loss:0.00, val_acc:0.97]
Epoch [50/100    avg_loss:0.00, val_acc:0.97]
Epoch [51/100    avg_loss:0.00, val_acc:0.97]
Epoch [52/100    avg_loss:0.00, val_acc:0.96]
Epoch [53/100    avg_loss:0.00, val_acc:0.97]
Epoch [54/100    avg_loss:0.00, val_acc:0.97]
Epoch [55/100    avg_loss:0.02, val_acc:0.96]
Epoch [56/100    avg_loss:0.02, val_acc:0.94]
Epoch [57/100    avg_loss:0.08, val_acc:0.93]
Epoch [58/100    avg_loss:0.07, val_acc:0.93]
Epoch [59/100    avg_loss:0.04, val_acc:0.94]
Epoch [60/100    avg_loss:0.06, val_acc:0.88]
Epoch [61/100    avg_loss:0.05, val_acc:0.95]
Epoch [62/100    avg_loss:0.01, val_acc:0.96]
Epoch [63/100    avg_loss:0.01, val_acc:0.95]
Epoch [64/100    avg_loss:0.00, val_acc:0.96]
Epoch [65/100    avg_loss:0.00, val_acc:0.96]
Epoch [66/100    avg_loss:0.00, val_acc:0.96]
Epoch [67/100    avg_loss:0.01, val_acc:0.97]
Epoch [68/100    avg_loss:0.01, val_acc:0.96]
Epoch [69/100    avg_loss:0.02, val_acc:0.96]
Epoch [70/100    avg_loss:0.00, val_acc:0.97]
Epoch [71/100    avg_loss:0.01, val_acc:0.96]
Epoch [72/100    avg_loss:0.00, val_acc:0.97]
Epoch [73/100    avg_loss:0.01, val_acc:0.95]
Epoch [74/100    avg_loss:0.03, val_acc:0.94]
Epoch [75/100    avg_loss:0.16, val_acc:0.92]
Epoch [76/100    avg_loss:0.10, val_acc:0.94]
Epoch [77/100    avg_loss:0.10, val_acc:0.93]
Epoch [78/100    avg_loss:0.04, val_acc:0.94]
Epoch [79/100    avg_loss:0.04, val_acc:0.94]
Epoch [80/100    avg_loss:0.03, val_acc:0.94]
Epoch [81/100    avg_loss:0.03, val_acc:0.95]
Epoch [82/100    avg_loss:0.02, val_acc:0.95]
Epoch [83/100    avg_loss:0.01, val_acc:0.95]
Epoch [84/100    avg_loss:0.01, val_acc:0.97]
Epoch [85/100    avg_loss:0.01, val_acc:0.95]
Epoch [86/100    avg_loss:0.05, val_acc:0.96]
Epoch [87/100    avg_loss:0.03, val_acc:0.96]
Epoch [88/100    avg_loss:0.03, val_acc:0.96]
Epoch [89/100    avg_loss:0.01, val_acc:0.96]
Epoch [90/100    avg_loss:0.01, val_acc:0.95]
Epoch [91/100    avg_loss:0.02, val_acc:0.95]
Epoch [92/100    avg_loss:0.02, val_acc:0.96]
Epoch [93/100    avg_loss:0.03, val_acc:0.83]
Epoch [94/100    avg_loss:0.13, val_acc:0.94]
Epoch [95/100    avg_loss:0.04, val_acc:0.94]
Epoch [96/100    avg_loss:0.02, val_acc:0.95]
Epoch [97/100    avg_loss:0.01, val_acc:0.96]
Epoch [98/100    avg_loss:0.01, val_acc:0.96]
Epoch [99/100    avg_loss:0.00, val_acc:0.96]
Epoch [100/100    avg_loss:0.01, val_acc:0.97]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0   36    0    0    0    1    0    0    3    0    1    0    0    0
     0    0    0]
 [   0    0 1266    7    0    0    0    0    0    0    5    7    0    0
     0    0    0]
 [   0    0   13  703    4    0    0    0    0    0    3    6   18    0
     0    0    0]
 [   0    0    4    2  207    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    6    0    0  425    0    0    0    0    0    0    0    0
     4    0    0]
 [   0    0    0    0    0    7  649    0    0    0    0    0    0    0
     1    0    0]
 [   0    0    0    0    0    0    0   25    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0  430    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    1    9    0    0    8    0    0    0    0
     0    0    0]
 [   0    0   23   13    0    0    9    1    0    0  791   33    0    0
     0    0    5]
 [   0    0   43   31    0    4    5    2    0    0   30 2090    5    0
     0    0    0]
 [   0    0   26    6    2    1    0    0    0    0   10    7  479    0
     0    1    2]
 [   0    0    0    0    0    0    0    0    0    0    0    3    0  182
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
  1129   10    0]
 [   0    0    0    1    0    2   40    0    0    1    0    1    1    1
    80  214    6]
 [   0    0    0    0    0    0    0    0    0    0    0    1    7    0
     0    0   76]]

Accuracy:
94.4173

F1 scores:
[   nan 0.9351 0.9497 0.9311 0.9718 0.9703 0.9481 0.9434 0.9965 0.5926
 0.9224 0.9592 0.9176 0.9891 0.9596 0.7483 0.8786]

Kappa:
0.9363
IndianPines数据集的结果如下
['93.51+-0.0' '94.97+-0.0' '93.11+-0.0' '97.18+-0.0' '97.03+-0.0'
 '94.81+-0.0' '94.34+-0.0' '99.65+-0.0' '59.26+-0.0' '92.24+-0.0'
 '95.92+-0.0' '91.76+-0.0' '98.91+-0.0' '95.96+-0.0' '74.83+-0.0'
 '87.86+-0.0']
acc_dataset [[94.41734417]]
OAMean 94.42 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:55--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:27
Validation dataloader:28
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:100
save_epoch:5
patch_size:17
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f4a33eeb890>
supervision:full
center_pixel:True
Network :
----------Training process----------
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:20:56--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:30
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:100
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f707fd0b5d0>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/100    avg_loss:1.98, val_acc:0.38]
Epoch [2/100    avg_loss:1.56, val_acc:0.49]
Epoch [3/100    avg_loss:1.38, val_acc:0.55]
Epoch [4/100    avg_loss:1.13, val_acc:0.62]
Epoch [5/100    avg_loss:0.94, val_acc:0.70]
Epoch [6/100    avg_loss:0.86, val_acc:0.67]
Epoch [7/100    avg_loss:0.68, val_acc:0.76]
Epoch [8/100    avg_loss:0.52, val_acc:0.78]
Epoch [9/100    avg_loss:0.43, val_acc:0.82]
Epoch [10/100    avg_loss:0.35, val_acc:0.87]
Epoch [11/100    avg_loss:0.26, val_acc:0.87]
Epoch [12/100    avg_loss:0.24, val_acc:0.87]
Epoch [13/100    avg_loss:0.17, val_acc:0.92]
Epoch [14/100    avg_loss:0.13, val_acc:0.91]
Epoch [15/100    avg_loss:0.12, val_acc:0.90]
Epoch [16/100    avg_loss:0.09, val_acc:0.92]
Epoch [17/100    avg_loss:0.12, val_acc:0.91]
Epoch [18/100    avg_loss:0.10, val_acc:0.93]
Epoch [19/100    avg_loss:0.15, val_acc:0.93]
Epoch [20/100    avg_loss:0.11, val_acc:0.93]
Epoch [21/100    avg_loss:0.06, val_acc:0.93]
Epoch [22/100    avg_loss:0.07, val_acc:0.92]
Epoch [23/100    avg_loss:0.06, val_acc:0.93]
Epoch [24/100    avg_loss:0.04, val_acc:0.94]
Epoch [25/100    avg_loss:0.05, val_acc:0.94]
Epoch [26/100    avg_loss:0.05, val_acc:0.94]
Epoch [27/100    avg_loss:0.11, val_acc:0.91]
Epoch [28/100    avg_loss:0.08, val_acc:0.94]
Epoch [29/100    avg_loss:0.05, val_acc:0.92]
Epoch [30/100    avg_loss:0.11, val_acc:0.94]
Epoch [31/100    avg_loss:0.05, val_acc:0.94]
Epoch [32/100    avg_loss:0.08, val_acc:0.95]
Epoch [33/100    avg_loss:0.03, val_acc:0.95]
Epoch [34/100    avg_loss:0.04, val_acc:0.95]
Epoch [35/100    avg_loss:0.06, val_acc:0.94]
Epoch [36/100    avg_loss:0.03, val_acc:0.95]
Epoch [37/100    avg_loss:0.01, val_acc:0.96]
Epoch [38/100    avg_loss:0.02, val_acc:0.92]
Epoch [39/100    avg_loss:0.08, val_acc:0.94]
Epoch [40/100    avg_loss:0.10, val_acc:0.93]
Epoch [41/100    avg_loss:0.05, val_acc:0.92]
Epoch [42/100    avg_loss:0.05, val_acc:0.95]
Epoch [43/100    avg_loss:0.03, val_acc:0.94]
Epoch [44/100    avg_loss:0.03, val_acc:0.96]
Epoch [45/100    avg_loss:0.01, val_acc:0.96]
Epoch [46/100    avg_loss:0.01, val_acc:0.95]
Epoch [47/100    avg_loss:0.01, val_acc:0.96]
Epoch [48/100    avg_loss:0.03, val_acc:0.94]
Epoch [49/100    avg_loss:0.01, val_acc:0.94]
Epoch [50/100    avg_loss:0.01, val_acc:0.94]
Epoch [51/100    avg_loss:0.20, val_acc:0.89]
Epoch [52/100    avg_loss:0.31, val_acc:0.86]
Epoch [53/100    avg_loss:0.20, val_acc:0.94]
Epoch [54/100    avg_loss:0.07, val_acc:0.92]
Epoch [55/100    avg_loss:0.04, val_acc:0.93]
Epoch [56/100    avg_loss:0.04, val_acc:0.95]
Epoch [57/100    avg_loss:0.02, val_acc:0.95]
Epoch [58/100    avg_loss:0.01, val_acc:0.96]
Epoch [59/100    avg_loss:0.01, val_acc:0.95]
Epoch [60/100    avg_loss:0.00, val_acc:0.94]
Epoch [61/100    avg_loss:0.01, val_acc:0.94]
Epoch [62/100    avg_loss:0.00, val_acc:0.95]
Epoch [63/100    avg_loss:0.01, val_acc:0.96]
Epoch [64/100    avg_loss:0.00, val_acc:0.97]
Epoch [65/100    avg_loss:0.00, val_acc:0.96]
Epoch [66/100    avg_loss:0.00, val_acc:0.96]
Epoch [67/100    avg_loss:0.01, val_acc:0.96]
Epoch [68/100    avg_loss:0.01, val_acc:0.95]
Epoch [69/100    avg_loss:0.00, val_acc:0.95]
Epoch [70/100    avg_loss:0.00, val_acc:0.95]
Epoch [71/100    avg_loss:0.00, val_acc:0.96]
Epoch [72/100    avg_loss:0.00, val_acc:0.97]
Epoch [73/100    avg_loss:0.02, val_acc:0.94]
Epoch [74/100    avg_loss:0.03, val_acc:0.96]
Epoch [75/100    avg_loss:0.03, val_acc:0.95]
Epoch [76/100    avg_loss:0.01, val_acc:0.94]
Epoch [77/100    avg_loss:0.02, val_acc:0.96]
Epoch [78/100    avg_loss:0.01, val_acc:0.96]
Epoch [79/100    avg_loss:0.00, val_acc:0.96]
Epoch [80/100    avg_loss:0.00, val_acc:0.96]
Epoch [81/100    avg_loss:0.00, val_acc:0.96]
Epoch [82/100    avg_loss:0.00, val_acc:0.97]
Epoch [83/100    avg_loss:0.00, val_acc:0.97]
Epoch [84/100    avg_loss:0.00, val_acc:0.96]
Epoch [85/100    avg_loss:0.00, val_acc:0.96]
Epoch [86/100    avg_loss:0.00, val_acc:0.96]
Epoch [87/100    avg_loss:0.01, val_acc:0.96]
Epoch [88/100    avg_loss:0.01, val_acc:0.96]
Epoch [89/100    avg_loss:0.01, val_acc:0.96]
Epoch [90/100    avg_loss:0.00, val_acc:0.96]
Epoch [91/100    avg_loss:0.00, val_acc:0.96]
Epoch [92/100    avg_loss:0.00, val_acc:0.96]
Epoch [93/100    avg_loss:0.00, val_acc:0.96]
Epoch [94/100    avg_loss:0.01, val_acc:0.95]
Epoch [95/100    avg_loss:0.05, val_acc:0.95]
Epoch [96/100    avg_loss:0.22, val_acc:0.89]
Epoch [97/100    avg_loss:0.19, val_acc:0.88]
Epoch [98/100    avg_loss:0.17, val_acc:0.93]
Epoch [99/100    avg_loss:0.07, val_acc:0.93]
Epoch [100/100    avg_loss:0.02, val_acc:0.96]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0   33    0    0    0    0    0    0    8    0    0    0    0    0
     0    0    0]
 [   0    0 1217    7    3    0    0    0    0    0   26   24    8    0
     0    0    0]
 [   0    0    2  736    0    0    0    0    0    0    3    2    4    0
     0    0    0]
 [   0    0    0   13  197    0    0    0    2    0    0    0    1    0
     0    0    0]
 [   0    0    4    0    0  427    0    0    0    0    0    0    0    0
     4    0    0]
 [   0    0    0    0    0    3  649    0    0    0    0    0    0    0
     5    0    0]
 [   0    0    0    0    0    7    0   18    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0  430    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0   12    0    0    0    0
     0    6    0]
 [   0    0   12    7    0    0    0    0    0    0  817   39    0    0
     0    0    0]
 [   0    0   10    8    0    0    0    0    0    0   23 2154    2    9
     4    0    0]
 [   0    0    8   11    0    0    0    0    0    0    1    8  499    0
     0    3    4]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0  185
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    1    0    0
  1122   16    0]
 [   0    1    0    0    0    0    0    0    0    0    0    0    0    0
    97  240    9]
 [   0    0    0    0    0    0    0    0    0    0    0    8    0    0
     0    0   76]]

Accuracy:
95.5230

F1 scores:
[   nan 0.88   0.959  0.9627 0.954  0.9794 0.9939 0.8372 0.9885 0.8
 0.9364 0.969  0.9523 0.9763 0.9464 0.7843 0.8786]

Kappa:
0.9489
IndianPines数据集的结果如下
['88.0+-0.0' '95.9+-0.0' '96.27+-0.0' '95.4+-0.0' '97.94+-0.0'
 '99.39+-0.0' '83.72+-0.0' '98.85+-0.0' '80.0+-0.0' '93.64+-0.0'
 '96.9+-0.0' '95.23+-0.0' '97.63+-0.0' '94.64+-0.0' '78.43+-0.0'
 '87.86+-0.0']
acc_dataset [[95.52303523]]
OAMean 95.52 +-0.00
creating ./logs/logs-2022-09-15IndianPines.txt
---------------------------------------------------------------------
-----------------------------Next run log----------------------------
---------------------------2022-09-15:21:42--------------------------
---------------------------------------------------------------------
Computation on CUDA GPU device 0
Setting up a new session...
Visdom successfully connected to server
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/train_gt.npy)
1024 samples selected for training(over 10249)
Training Percentage:0.1
Load train_gt successfully!(PATH:../dataset/IndianPines/0.10/test_gt.npy)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
Setting up a new session...
Visdom successfully connected to server
1024 samples selected for training(over 10249)
9225 samples selected for training(over 10249)
Running an experiment with the SSSERN_by_SE model, RUN [1/1]
RUN:0
1024 samples selected for validation(over 10249)
Running an experiment with the SSSERN_by_SE model
Train dataloader:30
Validation dataloader:29
----------Training parameters----------
dataset:IndianPines
model:SSSERN_by_SE
folder:../dataset/
cuda:0
run:1
sampling_mode:random
training_percentage:0.1
train_gt:False
test_gt:False
load_data:0.10
sample_nums:20
epoch:1
save_epoch:5
patch_size:11
lr:0.0005
class_balancing:True
test_stride:1
n_classes:17
n_bands:200
ignored_labels:[0]
device:cuda:0
weights:tensor([ 0.0000,  9.6000,  0.3357,  0.5783,  2.0000,  1.0000,  0.6575, 16.0000,
         1.0000, 24.0000,  0.4948,  0.1959,  0.8136,  2.4000,  0.3810,  1.2308,
         5.3333], device='cuda:0')
batch_size:32
validation_percentage:0.1
pca_bands:64
bands:200
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f2b2cfa0490>
supervision:full
center_pixel:True
Network :
----------Training process----------
Epoch [1/1    avg_loss:2.01, val_acc:0.41]
----------Training result----------

Confusion matrix:
[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0   35    0    0    0    0    0
     6    0    0]
 [   0    0    0    0    0    0    0    0    3    0    0 1271    0    0
    11    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0  737    0    0
    10    0    0]
 [   0    0    0    0    0    1    0    0    0    0    0  212    0    0
     0    0    0]
 [   0    0    0    0    0    8    0    0   25    0    0   18    0    0
   384    0    0]
 [   0    0    0    0    0    8    0    0    0    0    0   19    0    0
   630    0    0]
 [   0    0    0    0    0    0    0    0   19    0    0    0    0    0
     6    0    0]
 [   0    0    0    0    0    0    0    0  430    0    0    0    0    0
     0    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
    18    0    0]
 [   0    0    0    0    0    1    0    0    0    0    0  848    0    0
    26    0    0]
 [   0    0    0    0    0   10    0    0    3    0    0 2133    6    0
    45    0   13]
 [   0    0    5    0    0    1    0    0    2    0    2  499    8    0
    15    0    2]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
   185    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
  1139    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    0    0    0
   347    0    0]
 [   0    0    0    0    0    0    0    0    0    0    0    5    0    0
     0    0   79]]

Accuracy:
41.1599

F1 scores:
[   nan 0.     0.     0.     0.     0.0345 0.     0.     0.9081 0.
 0.     0.5365 0.0292 0.     0.5751 0.     0.8876]

Kappa:
0.2736
IndianPines数据集的结果如下
['0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '0.0+-0.0' '3.45+-0.0' '0.0+-0.0'
 '0.0+-0.0' '90.81+-0.0' '0.0+-0.0' '0.0+-0.0' '53.65+-0.0' '2.92+-0.0'
 '0.0+-0.0' '57.51+-0.0' '0.0+-0.0' '88.76+-0.0']
acc_dataset [[41.1598916]]
OAMean 41.16 +-0.00
